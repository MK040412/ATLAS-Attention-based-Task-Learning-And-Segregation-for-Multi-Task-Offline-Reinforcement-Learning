import numpy as np
from scipy.stats import multivariate_normal
from scipy.linalg import inv, det, LinAlgError
import torch
from typing import Dict, List, Tuple, Optional

class GaussianCluster:
    """ìˆ˜í•™ì ìœ¼ë¡œ ì •í™•í•œ ê°€ìš°ì‹œì•ˆ í´ëŸ¬ìŠ¤í„°"""
    def __init__(self, id: int, mu: np.ndarray, sigma: np.ndarray, N: int = 1):
        self.id = id
        self.mu = mu.copy()
        self.sigma = sigma.copy()  # ê³µë¶„ì‚° í–‰ë ¬
        self.N = N
        
        # ìˆ˜ì¹˜ì  ì•ˆì •ì„±ì„ ìœ„í•œ ì •ê·œí™”
        self.min_eigenval = 1e-6
        self._regularize_covariance()
        
        # ì¶©ë¶„ í†µê³„ëŸ‰ (ì˜¨ë¼ì¸ ì—…ë°ì´íŠ¸ìš©)
        self.sum_x = mu * N
        self.sum_xx = np.outer(mu, mu) * N + sigma * N
    
    def _regularize_covariance(self):
        """ê³µë¶„ì‚° í–‰ë ¬ ì •ê·œí™” (ìˆ˜ì¹˜ì  ì•ˆì •ì„±)"""
        try:
            # ê³ ìœ ê°’ ë¶„í•´
            eigenvals, eigenvecs = np.linalg.eigh(self.sigma)
            
            # ìµœì†Œ ê³ ìœ ê°’ ë³´ì¥
            eigenvals = np.maximum(eigenvals, self.min_eigenval)
            
            # ì¬êµ¬ì„±
            self.sigma = eigenvecs @ np.diag(eigenvals) @ eigenvecs.T
            
            # ëŒ€ì¹­ì„± ë³´ì¥
            self.sigma = (self.sigma + self.sigma.T) / 2
            
        except LinAlgError:
            # ì‹¤íŒ¨ì‹œ ëŒ€ê° í–‰ë ¬ë¡œ ì´ˆê¸°í™”
            self.sigma = np.eye(len(self.mu)) * 1e-3
    
    def update_online(self, z: np.ndarray):
        """ì˜¨ë¼ì¸ ì—…ë°ì´íŠ¸ (ìˆ˜í•™ì ìœ¼ë¡œ ì •í™•)"""
        self.N += 1
        
        # í‰ê·  ì—…ë°ì´íŠ¸
        old_mu = self.mu.copy()
        self.mu = old_mu + (z - old_mu) / self.N
        
        # ê³µë¶„ì‚° ì˜¨ë¼ì¸ ì—…ë°ì´íŠ¸ (Welford's algorithm)
        if self.N > 1:
            self.sigma = ((self.N - 2) * self.sigma + 
                         np.outer(z - old_mu, z - self.mu)) / (self.N - 1)
        
        self._regularize_covariance()

class MathematicalDPMM:
    """ìˆ˜í•™ì ìœ¼ë¡œ ì •í™•í•œ DPMM êµ¬í˜„"""
    
    def __init__(self, latent_dim: int, alpha: float = 1.0, 
                 tau_birth: float = -5.0, tau_merge_kl: float = 0.1):
        self.latent_dim = latent_dim
        self.alpha = alpha  # Dirichlet ë†ë„ ë§¤ê°œë³€ìˆ˜
        self.tau_birth = tau_birth  # Birth ì„ê³„ê°’ (ë¡œê·¸ ìš°ë„)
        self.tau_merge_kl = tau_merge_kl  # KL divergence merge ì„ê³„ê°’
        
        self.clusters: Dict[int, GaussianCluster] = {}
        self.next_cluster_id = 0
        
        # ì´ë²¤íŠ¸ ì¶”ì 
        self.birth_events = []
        self.merge_events = []
        self.assignment_history = []
        
        # ìˆ˜ì¹˜ì  ì•ˆì •ì„± íŒŒë¼ë¯¸í„°
        self.min_covariance = 1e-6
        self.max_kl_divergence = 1e6
        
        print(f"ğŸ§® Mathematical DPMM initialized:")
        print(f"  Latent dim: {latent_dim}, Î±: {alpha}")
        print(f"  Birth threshold: {tau_birth}, KL merge threshold: {tau_merge_kl}")
    
    def compute_log_likelihood(self, z: np.ndarray, cluster: GaussianCluster) -> float:
        """ìˆ˜í•™ì ìœ¼ë¡œ ì •í™•í•œ ë¡œê·¸ ìš°ë„ ê³„ì‚°"""
        try:
            # scipy.stats ì‚¬ìš© (ìˆ˜ì¹˜ì ìœ¼ë¡œ ì•ˆì •)
            log_prob = multivariate_normal.logpdf(z, cluster.mu, cluster.sigma)
            
            # NaN/Inf ì²´í¬
            if not np.isfinite(log_prob):
                return -1e6  # ë§¤ìš° ì‘ì€ ìš°ë„
            
            return log_prob
            
        except (LinAlgError, ValueError) as e:
            print(f"  âš ï¸ Likelihood computation failed: {e}")
            return -1e6
    
    def birth_criterion(self, z: np.ndarray) -> bool:
        """Birth criterion: max_k P(z|Î¸_k) < Ï„_birth"""
        if not self.clusters:
            return True
        
        try:
            max_log_likelihood = max([
                self.compute_log_likelihood(z, cluster) 
                for cluster in self.clusters.values()
            ])
            
            return max_log_likelihood < self.tau_birth
            
        except Exception as e:
            print(f"  âš ï¸ Birth criterion failed: {e}")
            return True  # ì•ˆì „í•˜ê²Œ ìƒˆ í´ëŸ¬ìŠ¤í„° ìƒì„±
    
    def kl_divergence_gaussian(self, cluster_i: GaussianCluster, 
                              cluster_j: GaussianCluster) -> float:
        """ë‘ ê°€ìš°ì‹œì•ˆ ê°„ KL divergence: KL(P_i || P_j)"""
        try:
            mu_i, sigma_i = cluster_i.mu, cluster_i.sigma
            mu_j, sigma_j = cluster_j.mu, cluster_j.sigma
            
            k = len(mu_i)  # ì°¨ì›
            
            # ìˆ˜ì¹˜ì  ì•ˆì •ì„±ì„ ìœ„í•œ ì •ê·œí™”
            sigma_i_reg = sigma_i + np.eye(k) * self.min_covariance
            sigma_j_reg = sigma_j + np.eye(k) * self.min_covariance
            
            # ì—­í–‰ë ¬ ê³„ì‚°
            sigma_j_inv = inv(sigma_j_reg)
            
            # í‰ê·  ì°¨ì´
            mu_diff = mu_j - mu_i
            
            # KL divergence ê³„ì‚°
            # KL(P||Q) = 0.5 * [tr(Î£_Q^{-1} Î£_P) + (Î¼_Q - Î¼_P)^T Î£_Q^{-1} (Î¼_Q - Î¼_P) - k + ln(det(Î£_Q)/det(Î£_P))]
            
            trace_term = np.trace(sigma_j_inv @ sigma_i_reg)
            quad_term = mu_diff.T @ sigma_j_inv @ mu_diff
            
            det_i = det(sigma_i_reg)
            det_j = det(sigma_j_reg)
            
            if det_i <= 0 or det_j <= 0:
                return self.max_kl_divergence
            
            log_det_term = np.log(det_j / det_i)
            
            kl = 0.5 * (trace_term + quad_term - k + log_det_term)
            
            # ìˆ˜ì¹˜ì  ì•ˆì •ì„± ì²´í¬
            if not np.isfinite(kl) or kl < 0:
                return self.max_kl_divergence
            
            return min(kl, self.max_kl_divergence)
            
        except (LinAlgError, ValueError) as e:
            print(f"  âš ï¸ KL divergence computation failed: {e}")
            return self.max_kl_divergence
    
    def symmetric_kl_divergence(self, cluster_i: GaussianCluster, 
                               cluster_j: GaussianCluster) -> float:
        """ëŒ€ì¹­ KL divergence: (KL(P_i||P_j) + KL(P_j||P_i)) / 2"""
        kl_ij = self.kl_divergence_gaussian(cluster_i, cluster_j)
        kl_ji = self.kl_divergence_gaussian(cluster_j, cluster_i)
        return (kl_ij + kl_ji) / 2.0
    
    def assign_point(self, z: np.ndarray) -> int:
        """í¬ì¸íŠ¸ë¥¼ í´ëŸ¬ìŠ¤í„°ì— í• ë‹¹"""
        z = np.array(z).flatten()
        
        # Birth criterion ì²´í¬
        if self.birth_criterion(z):
            cluster_id = self._create_new_cluster(z)
            print(f"  ğŸ£ Birth: New cluster {cluster_id}")
            return cluster_id
        
        # ê¸°ì¡´ í´ëŸ¬ìŠ¤í„° ì¤‘ ìµœì  ì„ íƒ
        best_cluster_id = None
        best_log_likelihood = -np.inf
        
        for cluster_id, cluster in self.clusters.items():
            log_likelihood = self.compute_log_likelihood(z, cluster)
            if log_likelihood > best_log_likelihood:
                best_log_likelihood = log_likelihood
                best_cluster_id = cluster_id
        
        # í´ëŸ¬ìŠ¤í„° ì—…ë°ì´íŠ¸
        if best_cluster_id is not None:
            self.clusters[best_cluster_id].update_online(z)
        
        self.assignment_history.append(best_cluster_id)
        return best_cluster_id
    
    def merge_clusters(self, verbose: bool = True) -> bool:
        """KL divergence ê¸°ë°˜ í´ëŸ¬ìŠ¤í„° ë³‘í•©"""
        if len(self.clusters) < 2:
            if verbose:
                print("  ğŸ”„ Merge: Not enough clusters")
            return False
        
        cluster_ids = list(self.clusters.keys())
        merge_candidates = []
        
        # ëª¨ë“  ìŒì˜ KL divergence ê³„ì‚°
        for i in range(len(cluster_ids)):
            for j in range(i + 1, len(cluster_ids)):
                id_i, id_j = cluster_ids[i], cluster_ids[j]
                
                if id_i not in self.clusters or id_j not in self.clusters:
                    continue
                
                cluster_i = self.clusters[id_i]
                cluster_j = self.clusters[id_j]
                
                kl_div = self.symmetric_kl_divergence(cluster_i, cluster_j)
                
                if kl_div < self.tau_merge_kl:
                    merge_candidates.append((id_i, id_j, kl_div))
        
        if not merge_candidates:
            if verbose:
                print(f"  ğŸ”„ Merge: No pairs within KL threshold {self.tau_merge_kl}")
            return False
        
        # KL divergence ìˆœìœ¼ë¡œ ì •ë ¬
        merge_candidates.sort(key=lambda x: x[2])
        
        merged_count = 0
        for id_i, id_j, kl_div in merge_candidates:
            if id_i not in self.clusters or id_j not in self.clusters:
                continue
            
            if verbose:
                print(f"  ğŸ”— Merging clusters {id_i} â†” {id_j} (KL: {kl_div:.6f})")
            
            self._merge_two_clusters(id_i, id_j)
            merged_count += 1
        
        if verbose:
            print(f"  âœ… Merged {merged_count} pairs, {len(self.clusters)} clusters remaining")
        
        return merged_count > 0
    
    def _create_new_cluster(self, z: np.ndarray) -> int:
        """ìƒˆ í´ëŸ¬ìŠ¤í„° ìƒì„±"""
        cluster_id = self.next_cluster_id
        self.next_cluster_id += 1
        
        # ì´ˆê¸° ê³µë¶„ì‚° í–‰ë ¬ (ëŒ€ê° í–‰ë ¬)
        initial_cov = np.eye(self.latent_dim) * 1e-3
        
        self.clusters[cluster_id] = GaussianCluster(
            id=cluster_id,
            mu=z.copy(),
            sigma=initial_cov,
            N=1
        )
        
        # Birth ì´ë²¤íŠ¸ ê¸°ë¡
        self.birth_events.append({
            'timestep': len(self.assignment_history),
            'cluster_id': cluster_id,
            'initial_mu': z.copy()
        })
        
        return cluster_id
    
    def _merge_two_clusters(self, id_i: int, id_j: int):
        """ë‘ í´ëŸ¬ìŠ¤í„° ë³‘í•© (ìˆ˜í•™ì ìœ¼ë¡œ ì •í™•)"""
        cluster_i = self.clusters[id_i]
        cluster_j = self.clusters[id_j]
        
        # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ìƒˆ íŒŒë¼ë¯¸í„° ê³„ì‚°
        N_total = cluster_i.N + cluster_j.N
        w_i = cluster_i.N / N_total
        w_j = cluster_j.N / N_total
        
        # ìƒˆ í‰ê· 
        new_mu = w_i * cluster_i.mu + w_j * cluster_j.mu
        
        # ìƒˆ ê³µë¶„ì‚° (mixture of Gaussians formula)
        diff_i = cluster_i.mu - new_mu
        diff_j = cluster_j.mu - new_mu
        
        new_sigma = (w_i * (cluster_i.sigma + np.outer(diff_i, diff_i)) +
                    w_j * (cluster_j.sigma + np.outer(diff_j, diff_j)))
        
        # ë” ì‘ì€ ID ìœ ì§€
        keep_id = min(id_i, id_j)
        remove_id = max(id_i, id_j)
        
        # ìƒˆ í´ëŸ¬ìŠ¤í„° ìƒì„±
        self.clusters[keep_id] = GaussianCluster(
            id=keep_id,
            mu=new_mu,
            sigma=new_sigma,
            N=N_total
        )
        
        # ì œê±°í•  í´ëŸ¬ìŠ¤í„° ì‚­ì œ
        del self.clusters[remove_id]
        
        # ë³‘í•© ì´ë²¤íŠ¸ ê¸°ë¡
        self.merge_events.append({
            'timestep': len(self.assignment_history),
            'old_clusters': [id_i, id_j],
            'new_cluster': keep_id,
            'kl_divergence': self.symmetric_kl_divergence(cluster_i, cluster_j)
        })
    
    def get_cluster_info(self) -> Dict:
        """í´ëŸ¬ìŠ¤í„° ì •ë³´ ë°˜í™˜"""
        return {
            'num_clusters': len(self.clusters),
            'cluster_sizes': {cid: cluster.N for cid, cluster in self.clusters.items()},
            'cluster_means': {cid: cluster.mu.tolist() for cid, cluster in self.clusters.items()},
            'total_births': len(self.birth_events),
            'total_merges': len(self.merge_events),
            'total_assignments': len(self.assignment_history)
        }
    
    def get_statistics(self) -> Dict:
        """ìƒì„¸ í†µê³„ ì •ë³´"""
        cluster_info = self.get_cluster_info()
        
        # í´ëŸ¬ìŠ¤í„° í¬ê¸° ë¶„í¬
        sizes = list(cluster_info['cluster_sizes'].values())
        
        stats = {
            'dpmm': {
                'num_clusters': cluster_info['num_clusters'],
                'total_births': cluster_info['total_births'],
                'total_merges': cluster_info['total_merges'],
                'cluster_sizes': sizes,
                'avg_cluster_size': np.mean(sizes) if sizes else 0,
                'std_cluster_size': np.std(sizes) if sizes else 0,
                'min_cluster_size': min(sizes) if sizes else 0,
                'max_cluster_size': max(sizes) if sizes else 0
            }
        }
        
        return stats
