import numpy as np
import torch
from gymnasium.spaces import Box
from isaaclab.envs import ManagerBasedRLEnv
from config import CONFIG
import isaaclab.sim as sim_utils
from isaaclab.assets import RigidObject, RigidObjectCfg
from isaaclab_tasks.manager_based.classic.ant.ant_env_cfg import AntEnvCfg, MySceneCfg

class IsaacAntPushEnv(ManagerBasedRLEnv):
    def __init__(self, custom_cfg=None, num_envs: int = 1):
        print(f"ğŸ—ï¸ Creating Ant Push Environment with Blue Cube")
        
        # Build base IsaacLab Ant config
        cfg = AntEnvCfg()
        cfg.scene = MySceneCfg(num_envs=num_envs, env_spacing=cfg.scene.env_spacing)
        cfg.sim.device = str(CONFIG.device)
        super().__init__(cfg=cfg)

        # Store custom params
        c = custom_cfg or {}
        self.cube_position = np.array(c.get('cube_position', [2.0, 0.0, 0.1]), dtype=np.float32)
        self.goal_position = np.array(c.get('goal_position', [3.0, 0.0, 0.1]), dtype=np.float32)
        
        print(f"  Cube position: {self.cube_position}")
        print(f"  Goal position: {self.goal_position}")

        # --- BLUE CUBE CREATION ---
        try:
            # Spawn cube as RigidObject using CuboidCfg
            spawn_cfg = sim_utils.CuboidCfg(
                size=(0.2, 0.2, 0.2),  # 20cm cube
                rigid_props=sim_utils.RigidBodyPropertiesCfg(),
                mass_props=sim_utils.MassPropertiesCfg(mass=1.0),
                collision_props=sim_utils.CollisionPropertiesCfg(),
                visual_material=sim_utils.PreviewSurfaceCfg(
                    diffuse_color=(0.0, 0.0, 1.0),  # Blue color
                    metallic=0.1
                )
            )
            
            cube_cfg = RigidObjectCfg(
                prim_path="/World/envs/env_.*/Cube",  # Proper path pattern
                spawn=spawn_cfg,
                init_state=RigidObjectCfg.InitialStateCfg(
                    pos=(*self.cube_position,),  # Initial position
                ),
            )
            
            # Create and initialize rigid object
            self.cube = RigidObject(cfg=cube_cfg)
            print("âœ… Blue cube created successfully")
            
        except Exception as e:
            print(f"Warning: Cube creation failed: {e}")
            self.cube = None

        # Redefine observation space: policy obs + cube_pos(3) + goal_pos(3)
        base_shape = self.observation_space['policy'].shape
        base_dim = int(np.prod(base_shape))
        full_dim = base_dim + 3 + 3  # +cube_pos +goal_pos
        self.observation_space = Box(
            low=-np.inf, high=np.inf, shape=(full_dim,), dtype=np.float32
        )
        print(f"âœ… Observation space: {self.observation_space.shape}")

    def _tensor_to_numpy(self, tensor):
        """í…ì„œë¥¼ numpy ë°°ì—´ë¡œ ì•ˆì „í•˜ê²Œ ë³€í™˜"""
        if torch.is_tensor(tensor):
            return tensor.detach().cpu().numpy()
        elif isinstance(tensor, np.ndarray):
            return tensor
        else:
            return np.array(tensor)

    def _prepare_action(self, action):
        """ì•¡ì…˜ì„ í™˜ê²½ì— ë§ëŠ” í˜•íƒœë¡œ ë³€í™˜"""
        # numpy arrayë¡œ ë³€í™˜
        if torch.is_tensor(action):
            action = self._tensor_to_numpy(action)
        elif not isinstance(action, np.ndarray):
            action = np.array(action)
        
        # ì°¨ì› í™•ì¸ ë° ì¡°ì •
        if action.ndim == 1:
            # ë‹¨ì¼ í™˜ê²½ìš© actionì„ ë‹¤ì¤‘ í™˜ê²½ìš©ìœ¼ë¡œ í™•ì¥
            action = action.reshape(1, -1)
        
        # torch tensorë¡œ ë³€í™˜ (Isaac Labì´ ê¸°ëŒ€í•˜ëŠ” í˜•íƒœ)
        action_tensor = torch.FloatTensor(action).to(CONFIG.device)
        return action_tensor

    def _get_cube_position(self):
        """íë¸Œì˜ í˜„ì¬ ìœ„ì¹˜ ê°€ì ¸ì˜¤ê¸°"""
        if self.cube is not None:
            try:
                cube_pos_tensor = self.cube.data.root_pos_w[0]
                cube_pos = self._tensor_to_numpy(cube_pos_tensor)[:3]
                return np.array(cube_pos, dtype=np.float32)
            except:
                pass
        # íë¸Œê°€ ì—†ê±°ë‚˜ ì˜¤ë¥˜ ì‹œ ì´ˆê¸° ìœ„ì¹˜ ë°˜í™˜
        return self.cube_position.copy()

    def _merge_obs(self, obs_dict):
        """ê´€ì¸¡ê°’ ë³‘í•©: [policy_obs, cube_pos, goal_pos]"""
        base = obs_dict['policy']
        
        # í…ì„œë¥¼ numpyë¡œ ë³€í™˜
        if torch.is_tensor(base):
            base = self._tensor_to_numpy(base)
        
        # íë¸Œ ìœ„ì¹˜ ê°€ì ¸ì˜¤ê¸°
        cube_pos = self._get_cube_position()
        
        # ëª¨ë“  ê²ƒì„ numpy ë°°ì—´ë¡œ ë³€í™˜
        base = np.array(base, dtype=np.float32).flatten()
        cube_pos = np.array(cube_pos, dtype=np.float32)
        goal_pos = np.array(self.goal_position, dtype=np.float32)
        
        return np.concatenate([base, cube_pos, goal_pos], axis=0)

    def reset(self):
        obs_dict, info = super().reset()
        merged = self._merge_obs(obs_dict)
        print(f"ğŸ”„ Environment reset - State shape: {merged.shape}")
        return merged, info

    def step(self, action):
        try:
            # ì•¡ì…˜ì„ ì ì ˆí•œ í˜•íƒœë¡œ ë³€í™˜
            action_tensor = self._prepare_action(action)
            
            # í™˜ê²½ ìŠ¤í… ì‹¤í–‰
            obs_dict, _, term, trunc, info = super().step(action_tensor)
            
        except Exception as e:
            print(f"Environment step error: {e}")
            # ë”ë¯¸ ê°’ ë°˜í™˜
            obs_dict = {'policy': np.zeros(self.observation_space.shape[0] - 6)}
            term = True
            trunc = False
            info = {}
        
        obs = self._merge_obs(obs_dict)
        
        # ë³´ìƒ ê³„ì‚°
        ant_base = obs[:3]  # Antì˜ ê¸°ë³¸ ìœ„ì¹˜
        cube_pos = obs[-6:-3]  # íë¸Œ ìœ„ì¹˜
        goal_pos = obs[-3:]   # ëª©í‘œ ìœ„ì¹˜
        
        # ë³´ìƒ: íë¸Œë¥¼ ëª©í‘œë¡œ ë°€ê¸° + ê°œë¯¸ê°€ íë¸Œì— ê°€ê¹Œì´ ê°€ê¸°
        r_push = -np.linalg.norm(cube_pos - goal_pos)  # íë¸Œ-ëª©í‘œ ê±°ë¦¬
        r_near = -0.1 * np.linalg.norm(ant_base - cube_pos)  # ê°œë¯¸-íë¸Œ ê±°ë¦¬
        reward = float(r_push + r_near)
        
        done = bool(term or trunc)
        
        return obs, reward, done, info

    def get_action_dim(self):
        """ì•¡ì…˜ ì°¨ì› ë°˜í™˜"""
        if hasattr(self.action_space, 'shape'):
            return self.action_space.shape[1] if len(self.action_space.shape) == 2 else self.action_space.shape[0]
        return 8  # ê¸°ë³¸ê°’

    def close(self):
        """í™˜ê²½ ì •ë¦¬"""
        try:
            super().close()
            print("âœ… Environment closed safely")
        except Exception as e:
            print(f"Warning during close: {e}")
