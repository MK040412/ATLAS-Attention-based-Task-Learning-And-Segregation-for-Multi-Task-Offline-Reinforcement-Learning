class RigorousDPMM:
    def __init__(self, latent_dim: int, alpha: float = 1.0, sigma_sq: float = 1.0,
                 tau_birth: float = 1e-4, tau_merge: float = 0.5):
        self.latent_dim = latent_dim
        self.alpha = alpha
        self.sigma_sq = sigma_sq
        self.tau_birth = tau_birth
        self.tau_merge = tau_merge
        
        self.clusters: Dict[int, GaussianCluster] = {}
        self.next_cluster_id = 0
        self.assignment_cache = {}  # ìºì‹œ ì¶”ê°€
        
        # ì´ë²¤íŠ¸ ì¶”ì 
        self.birth_events = []
        self.merge_events = []
        self.assignment_history = []
        
        print(f"ðŸ§  Rigorous DPMM initialized:")
        print(f"  Latent dim: {latent_dim}, Î±: {alpha}, ÏƒÂ²: {sigma_sq}")
        print(f"  Birth threshold: {tau_birth}, Merge threshold: {tau_merge}")
    
    def assign(self, z: np.ndarray) -> int:
        """í¬ì¸íŠ¸ë¥¼ í´ëŸ¬ìŠ¤í„°ì— í• ë‹¹ (ìºì‹œ ì‚¬ìš©)"""
        # ìºì‹œ í‚¤ ìƒì„± (ë¶€ë™ì†Œìˆ˜ì  ì •ë°€ë„ ë¬¸ì œ í•´ê²°)
        cache_key = tuple(np.round(z, decimals=6))
        
        # ìºì‹œì—ì„œ í™•ì¸
        if cache_key in self.assignment_cache:
            cached_cluster = self.assignment_cache[cache_key]
            # í´ëŸ¬ìŠ¤í„°ê°€ ì—¬ì „ížˆ ì¡´ìž¬í•˜ëŠ”ì§€ í™•ì¸
            if cached_cluster in self.clusters:
                return cached_cluster
            else:
                # ìºì‹œì—ì„œ ì œê±°
                del self.assignment_cache[cache_key]
        
        if len(self.clusters) == 0:
            # ì²« ë²ˆì§¸ í´ëŸ¬ìŠ¤í„° ìƒì„±
            cluster_id = self._create_new_cluster(z)
            self.assignment_cache[cache_key] = cluster_id
            return cluster_id
        
        # ê¸°ì¡´ í´ëŸ¬ìŠ¤í„°ë“¤ê³¼ì˜ ìš°ë„ ê³„ì‚°
        max_likelihood = -np.inf
        best_cluster = None
        
        for cluster_id, cluster in self.clusters.items():
            likelihood = self._gaussian_likelihood(z, cluster)
            if likelihood > max_likelihood:
                max_likelihood = likelihood
                best_cluster = cluster_id
        
        # Birth heuristic ê²€ì‚¬
        if max_likelihood < self.tau_birth:
            # ìƒˆ í´ëŸ¬ìŠ¤í„° ìƒì„±
            new_cluster_id = self._create_new_cluster(z)
            self.assignment_cache[cache_key] = new_cluster_id
            print(f"ðŸ£ Birth triggered! New cluster {new_cluster_id} (likelihood: {max_likelihood:.2e})")
            return new_cluster_id
        else:
            # ê¸°ì¡´ í´ëŸ¬ìŠ¤í„°ì— í• ë‹¹
            self._update_cluster(best_cluster, z)
            self.assignment_cache[cache_key] = best_cluster
            return best_cluster
    
    def merge(self):
        """í´ëŸ¬ìŠ¤í„° ë³‘í•© (ìºì‹œ ì—…ë°ì´íŠ¸ í¬í•¨)"""
        if len(self.clusters) < 2:
            return
        
        cluster_ids = list(self.clusters.keys())
        merged_pairs = []
        
        for i in range(len(cluster_ids)):
            for j in range(i + 1, len(cluster_ids)):
                id1, id2 = cluster_ids[i], cluster_ids[j]
                
                if id1 not in self.clusters or id2 not in self.clusters:
                    continue
                
                cluster1 = self.clusters[id1]
                cluster2 = self.clusters[id2]
                
                # ê±°ë¦¬ ê³„ì‚°
                distance = np.linalg.norm(cluster1.mu - cluster2.mu)
                
                if distance < self.tau_merge:
                    merged_pairs.append((id1, id2, distance))
        
        # ê±°ë¦¬ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ê°€ìž¥ ê°€ê¹Œìš´ ê²ƒë¶€í„° ë³‘í•©
        merged_pairs.sort(key=lambda x: x[2])
        
        for id1, id2, distance in merged_pairs:
            if id1 in self.clusters and id2 in self.clusters:
                self._merge_clusters(id1, id2)
                
                # ìºì‹œ ì—…ë°ì´íŠ¸
                self._update_cache_after_merge(id1, id2)
    
    def _update_cache_after_merge(self, old_id1: int, old_id2: int):
        """ë³‘í•© í›„ ìºì‹œ ì—…ë°ì´íŠ¸"""
        # ë³‘í•©ëœ í´ëŸ¬ìŠ¤í„°ë“¤ì„ ì°¸ì¡°í•˜ëŠ” ìºì‹œ ì—”íŠ¸ë¦¬ë“¤ì„ ì°¾ì•„ì„œ ì—…ë°ì´íŠ¸
        keys_to_update = []
        for cache_key, cluster_id in self.assignment_cache.items():
            if cluster_id == old_id1 or cluster_id == old_id2:
                keys_to_update.append(cache_key)
        
        # ìƒˆë¡œìš´ í´ëŸ¬ìŠ¤í„° ID ì°¾ê¸° (ë³‘í•© í›„ ë‚¨ì€ í´ëŸ¬ìŠ¤í„°)
        remaining_clusters = set(self.clusters.keys())
        new_cluster_id = None
        
        # ê°€ìž¥ ìµœê·¼ì— ìƒì„±ëœ í´ëŸ¬ìŠ¤í„°ë¥¼ ìƒˆ IDë¡œ ì‚¬ìš©
        if remaining_clusters:
            new_cluster_id = max(remaining_clusters)
        
        # ìºì‹œ ì—…ë°ì´íŠ¸
        for cache_key in keys_to_update:
            if new_cluster_id is not None:
                self.assignment_cache[cache_key] = new_cluster_id
            else:
                del self.assignment_cache[cache_key]