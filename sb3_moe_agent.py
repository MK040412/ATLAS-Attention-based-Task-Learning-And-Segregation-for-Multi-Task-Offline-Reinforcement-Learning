import torch
import torch.nn as nn
import numpy as np
from typing import List, Dict, Any, Tuple, Optional
from sb3_moe_expert import SB3SACExpert
from fixed_simple_gym_wrapper import SimpleAntPushWrapper

class FusionEncoder(nn.Module):
    """ëª…ë ¹ì–´-ìƒíƒœ ìœµí•© ì¸ì½”ë”"""
    def __init__(self, instr_dim: int, state_dim: int, latent_dim: int):
        super().__init__()
        self.instr_dim = instr_dim
        self.state_dim = state_dim
        self.latent_dim = latent_dim
        
        # ìˆ˜ì‹: z = MLP([e; s])
        input_dim = instr_dim + state_dim
        self.mlp = nn.Sequential(
            nn.Linear(input_dim, 256),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Linear(128, latent_dim)
        )
        
        print(f"ğŸ”— FusionEncoder: {instr_dim} + {state_dim} -> {latent_dim}")
    
    def forward(self, instr_emb: torch.Tensor, state_obs: torch.Tensor) -> torch.Tensor:
        """ìœµí•© ì¸ì½”ë”©"""
        # ì°¨ì› ì •ë¦¬
        if instr_emb.dim() == 1:
            instr_emb = instr_emb.unsqueeze(0)
        if state_obs.dim() == 1:
            state_obs = state_obs.unsqueeze(0)
        
        # ì—°ê²° ë° ì¸ì½”ë”©
        combined = torch.cat([instr_emb, state_obs], dim=-1)
        latent = self.mlp(combined)
        
        return latent.squeeze(0) if latent.size(0) == 1 else latent

class SimpleDPMM:
    """ê°„ë‹¨í•œ DPMM (Boolean Tensor ë¬¸ì œ ìˆ˜ì •)"""
    def __init__(self, latent_dim: int, alpha: float = 1.0, base_var: float = 1.0, 
                 tau_birth: float = 2.0, tau_merge: float = 0.5):
        self.latent_dim = latent_dim
        self.alpha = alpha
        self.base_var = base_var
        self.tau_birth = tau_birth
        self.tau_merge = tau_merge
        
        self.clusters = []
        self.cluster_counts = []
        self.assignments = []
        
        # í†µê³„ ì¶”ì 
        self.birth_events = []
        self.merge_events = []
        
    def assign_and_update(self, z: np.ndarray) -> int:
        """ìƒˆ ë°ì´í„°ë¥¼ í´ëŸ¬ìŠ¤í„°ì— í• ë‹¹í•˜ê³  ì—…ë°ì´íŠ¸"""
        z = np.array(z).flatten()
        
        if len(self.clusters) == 0:
            self.clusters.append(z.copy())
            self.cluster_counts.append(1)
            self.assignments.append(0)
            self.birth_events.append(len(self.assignments))
            return 0
        
        # ê° í´ëŸ¬ìŠ¤í„°ì™€ì˜ ê±°ë¦¬ ê³„ì‚°
        distances = []
        for cluster_center in self.clusters:
            dist = np.linalg.norm(z - cluster_center)
            distances.append(dist)
        
        min_dist = min(distances)
        closest_cluster = distances.index(min_dist)
        
        # Birth ì¡°ê±´ (ê±°ë¦¬ ê¸°ë°˜)
        if min_dist > self.tau_birth:
            # ìƒˆ í´ëŸ¬ìŠ¤í„° ìƒì„±
            cluster_id = len(self.clusters)
            self.clusters.append(z.copy())
            self.cluster_counts.append(1)
            self.birth_events.append(len(self.assignments))
            print(f"  ğŸ£ New cluster {cluster_id} created (distance: {min_dist:.3f})")
        else:
            # ê¸°ì¡´ í´ëŸ¬ìŠ¤í„°ì— í• ë‹¹
            cluster_id = closest_cluster
            self.cluster_counts[cluster_id] += 1
            
            # í´ëŸ¬ìŠ¤í„° ì¤‘ì‹¬ ì—…ë°ì´íŠ¸
            alpha = 0.1
            self.clusters[cluster_id] = (1 - alpha) * self.clusters[cluster_id] + alpha * z
        
        self.assignments.append(cluster_id)
        return cluster_id
    
    def merge_clusters(self, verbose: bool = False) -> bool:
        """í´ëŸ¬ìŠ¤í„° ë³‘í•©"""
        if len(self.clusters) < 2:
            return False
        
        merged = False
        
        # ê°€ì¥ ê°€ê¹Œìš´ í´ëŸ¬ìŠ¤í„° ìŒ ì°¾ê¸°
        min_distance = float('inf')
        merge_pair = None
        
        for i in range(len(self.clusters)):
            for j in range(i + 1, len(self.clusters)):
                dist = np.linalg.norm(self.clusters[i] - self.clusters[j])
                if dist < min_distance:
                    min_distance = dist
                    merge_pair = (i, j)
        
        # ë³‘í•© ì¡°ê±´
        if merge_pair and min_distance < self.tau_merge:
            i, j = merge_pair
            
            # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ìƒˆ ì¤‘ì‹¬ ê³„ì‚°
            total_count = self.cluster_counts[i] + self.cluster_counts[j]
            new_center = (self.cluster_counts[i] * self.clusters[i] + 
                         self.cluster_counts[j] * self.clusters[j]) / total_count
            
            # ë” ì‘ì€ ì¸ë±ìŠ¤ì— ë³‘í•©
            keep_idx = min(i, j)
            remove_idx = max(i, j)
            
            self.clusters[keep_idx] = new_center
            self.cluster_counts[keep_idx] = total_count
            
            # ì œê±°í•  í´ëŸ¬ìŠ¤í„° ì‚­ì œ
            del self.clusters[remove_idx]
            del self.cluster_counts[remove_idx]
            
            # í• ë‹¹ ê¸°ë¡ ì—…ë°ì´íŠ¸ (remove_idxë¥¼ keep_idxë¡œ ë³€ê²½)
            self.assignments = [keep_idx if x == remove_idx else (x-1 if x > remove_idx else x) 
                              for x in self.assignments]
            
            self.merge_events.append(len(self.assignments))
            merged = True
            
            if verbose:
                print(f"  ğŸ”— Merged clusters {i}â†”{j} â†’ {keep_idx} (distance: {min_distance:.3f})")
        
        return merged
    
    def get_num_clusters(self) -> int:
        return len(self.clusters)
    
    def get_cluster_info(self) -> Dict[str, Any]:
        return {
            'num_clusters': len(self.clusters),
            'cluster_counts': self.cluster_counts.copy(),
            'total_assignments': len(self.assignments),
            'total_births': len(self.birth_events),
            'total_merges': len(self.merge_events)
        }

class SB3MoEAgent:
    """SB3 ê¸°ë°˜ MoE SAC ì—ì´ì „íŠ¸"""
    def __init__(self, env: SimpleAntPushWrapper, instr_dim: int, 
                 latent_dim: int = 32, cluster_threshold: float = 2.0):
        self.env = env
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # ì°¨ì› ì •ë³´
        self.state_dim = env.observation_space.shape[0]
        self.action_dim = env.action_space.shape[0]
        self.instr_dim = instr_dim
        self.latent_dim = latent_dim
        self.cluster_threshold = cluster_threshold
        
        # ìœµí•© ì¸ì½”ë”
        self.fusion_encoder = FusionEncoder(
            instr_dim=instr_dim,
            state_dim=self.state_dim,
            latent_dim=latent_dim
        ).to(self.device)
        
        # DPMM
        self.dpmm = SimpleDPMM(latent_dim=latent_dim)
        
        # ì „ë¬¸ê°€ë“¤
        self.experts: List[SB3SACExpert] = []
        
        print(f"ğŸ­ SB3 MoE Agent initialized:")
        print(f"  State dim: {self.state_dim}")
        print(f"  Action dim: {self.action_dim}")
        print(f"  Instruction dim: {instr_dim}")
        print(f"  Latent dim: {latent_dim}")
    
    def _create_expert(self) -> SB3SACExpert:
        """ìƒˆ ì „ë¬¸ê°€ ìƒì„±"""
        expert_id = len(self.experts)
        expert = SB3SACExpert(
            env=self.env,
            expert_id=expert_id,
            learning_rate=3e-4,
            buffer_size=5000
        )
        self.experts.append(expert)
        print(f"  â• Created expert {expert_id}")
        return expert
    
    def select_action(self, state: np.ndarray, instruction_emb: np.ndarray, 
                     deterministic: bool = False) -> Tuple[np.ndarray, int]:
        """í–‰ë™ ì„ íƒ (Tensor ë¬¸ì œ ìˆ˜ì •)"""
        # Tensor ë³€í™˜ ë° ì°¨ì› ì •ë¦¬
        if not isinstance(state, torch.Tensor):
            state_tensor = torch.FloatTensor(state).to(self.device)
        else:
            state_tensor = state.to(self.device)
        
        if not isinstance(instruction_emb, torch.Tensor):
            instr_tensor = torch.FloatTensor(instruction_emb).to(self.device)
        else:
            instr_tensor = instruction_emb.to(self.device)
        
        # ì°¨ì› ì •ë¦¬ (ë°°ì¹˜ ì°¨ì› ì œê±°)
        if state_tensor.dim() > 1:
            state_tensor = state_tensor.squeeze()
        if instr_tensor.dim() > 1:
            instr_tensor = instr_tensor.squeeze()
        
        # ìœµí•©ëœ ì ì¬ í‘œí˜„ ìƒì„±
        try:
            with torch.no_grad():
                latent = self.fusion_encoder(instr_tensor, state_tensor)
                # Tensorë¥¼ numpyë¡œ ì•ˆì „í•˜ê²Œ ë³€í™˜
                if hasattr(latent, 'cpu'):
                    latent_np = latent.cpu().numpy()
                else:
                    latent_np = np.array(latent)
                
                # 1ì°¨ì›ìœ¼ë¡œ í‰íƒ„í™”
                latent_np = latent_np.flatten()
        except Exception as e:
            print(f"âš ï¸ Fusion encoder error: {e}")
            latent_np = np.random.randn(self.latent_dim)
        
        # DPMM í´ëŸ¬ìŠ¤í„° í• ë‹¹
        cluster_id = self.dpmm.assign_and_update(latent_np)
        
        # ì „ë¬¸ê°€ê°€ ì—†ìœ¼ë©´ ìƒì„±
        if cluster_id not in self.experts:
            self._create_expert(cluster_id)
        
        # í•´ë‹¹ ì „ë¬¸ê°€ë¡œë¶€í„° í–‰ë™ ì„ íƒ
        expert = self.experts[cluster_id]
        
        try:
            # ìƒíƒœë¥¼ ì˜¬ë°”ë¥¸ í˜•íƒœë¡œ ë³€í™˜
            if isinstance(state, np.ndarray):
                obs_for_expert = state.copy()
            else:
                obs_for_expert = np.array(state)
            
            # ì°¨ì› í™•ì¸ ë° ì¡°ì •
            if len(obs_for_expert.shape) == 0:
                obs_for_expert = obs_for_expert.reshape(1)
            elif len(obs_for_expert.shape) > 1:
                obs_for_expert = obs_for_expert.flatten()
            
            # SB3 predict í˜¸ì¶œ (Boolean Tensor ë¬¸ì œ ë°©ì§€)
            action, _ = expert.predict(obs_for_expert, deterministic=deterministic)
            
            # ì•¡ì…˜ í›„ì²˜ë¦¬
            if isinstance(action, np.ndarray):
                if len(action.shape) > 1:
                    action = action.flatten()
            else:
                action = np.array([action])
                
        except Exception as e:
            print(f"âš ï¸ Expert prediction error: {e}")
            # í´ë°±: ëœë¤ ì•¡ì…˜
            action = np.random.uniform(-1, 1, self.action_dim)
        
        return action, cluster_id
    
    def store_experience(self, state, action, reward, next_state, done, cluster_id):
        """ê²½í—˜ ì €ì¥ (Tensor ì•ˆì „ ì²˜ë¦¬)"""
        if cluster_id in self.experts:
            expert = self.experts[cluster_id]
            
            try:
                # ëª¨ë“  ì…ë ¥ì„ numpyë¡œ ë³€í™˜
                if hasattr(state, 'cpu'):
                    state = state.cpu().numpy()
                if hasattr(next_state, 'cpu'):
                    next_state = next_state.cpu().numpy()
                if hasattr(action, 'cpu'):
                    action = action.cpu().numpy()
                if hasattr(reward, 'item'):
                    reward = reward.item()
                if hasattr(done, 'item'):
                    done = done.item()
                
                # ì°¨ì› ì •ë¦¬
                if isinstance(state, np.ndarray) and len(state.shape) > 1:
                    state = state.flatten()
                if isinstance(next_state, np.ndarray) and len(next_state.shape) > 1:
                    next_state = next_state.flatten()
                if isinstance(action, np.ndarray) and len(action.shape) > 1:
                    action = action.flatten()
                
                # ë¦¬í”Œë ˆì´ ë²„í¼ì— ì €ì¥
                if hasattr(expert, 'replay_buffer'):
                    expert.replay_buffer.add(state, action, reward, next_state, done)
                else:
                    print(f"âš ï¸ Expert {cluster_id} has no replay buffer")
                    
            except Exception as e:
                print(f"âš ï¸ Experience storage error for expert {cluster_id}: {e}")
    
    def update_experts(self, batch_size: int = 64) -> Dict[str, Any]:
        """ëª¨ë“  ì „ë¬¸ê°€ ì—…ë°ì´íŠ¸"""
        update_results = {}
        
        for expert in self.experts:
            result = expert.update(batch_size)
            if result:
                update_results[f"expert_{expert.expert_id}"] = result
        
        return update_results
    
    def get_info(self) -> Dict[str, Any]:
        """ì—ì´ì „íŠ¸ ì •ë³´"""
        expert_info = [expert.get_info() for expert in self.experts]
        dpmm_info = self.dpmm.get_info()
        
        return {
            'num_experts': len(self.experts),
            'experts': expert_info,
            'dpmm': dpmm_info,
            'total_buffer_size': sum(info['buffer_size'] for info in expert_info)
        }
    
    def save(self, save_dir: str):
        """ëª¨ë¸ ì €ì¥"""
        import os
        os.makedirs(save_dir, exist_ok=True)
        
        # ìœµí•© ì¸ì½”ë” ì €ì¥
        fusion_path = os.path.join(save_dir, "fusion_encoder.pt")
        torch.save(self.fusion_encoder.state_dict(), fusion_path)
        
        # DPMM ìƒíƒœ ì €ì¥
        dpmm_path = os.path.join(save_dir, "dpmm_state.pt")
        torch.save({
            'clusters': self.dpmm.clusters,
            'cluster_counts': self.dpmm.cluster_counts,
            'assignments': self.dpmm.assignments,
            'latent_dim': self.dpmm.latent_dim,
            'alpha': self.dpmm.alpha,
            'base_var': self.dpmm.base_var
        }, dpmm_path)
        
        # ê° ì „ë¬¸ê°€ ì €ì¥
        for i, expert in enumerate(self.experts):
            expert_path = os.path.join(save_dir, f"expert_{i}")
            expert.save(expert_path)
        
        # ë©”íƒ€ ì •ë³´ ì €ì¥
        meta_path = os.path.join(save_dir, "meta_info.pt")
        torch.save({
            'state_dim': self.state_dim,
            'action_dim': self.action_dim,
            'instr_dim': self.instr_dim,
            'latent_dim': self.latent_dim,
            'cluster_threshold': self.cluster_threshold,
            'num_experts': len(self.experts)
        }, meta_path)
        
        print(f"ğŸ’¾ SB3 MoE Agent saved to {save_dir}")
    
    def load(self, save_dir: str):
        """ëª¨ë¸ ë¡œë“œ"""
        import os
        
        # ë©”íƒ€ ì •ë³´ ë¡œë“œ
        meta_path = os.path.join(save_dir, "meta_info.pt")
        if os.path.exists(meta_path):
            meta_info = torch.load(meta_path)
            print(f"ğŸ“‚ Loading agent with {meta_info['num_experts']} experts")
        
        # ìœµí•© ì¸ì½”ë” ë¡œë“œ
        fusion_path = os.path.join(save_dir, "fusion_encoder.pt")
        if os.path.exists(fusion_path):
            self.fusion_encoder.load_state_dict(torch.load(fusion_path))
            print(f"  âœ… Fusion encoder loaded")
        
        # DPMM ìƒíƒœ ë¡œë“œ
        dpmm_path = os.path.join(save_dir, "dpmm_state.pt")
        if os.path.exists(dpmm_path):
            dpmm_state = torch.load(dpmm_path)
            self.dpmm.clusters = dpmm_state['clusters']
            self.dpmm.cluster_counts = dpmm_state['cluster_counts']
            self.dpmm.assignments = dpmm_state['assignments']
            print(f"  âœ… DPMM state loaded: {len(self.dpmm.clusters)} clusters")
        
        # ì „ë¬¸ê°€ë“¤ ë¡œë“œ
        self.experts = []
        expert_idx = 0
        while True:
            expert_path = os.path.join(save_dir, f"expert_{expert_idx}")
            if os.path.exists(expert_path + ".zip"):  # SB3 saves as .zip
                expert = SB3SACExpert(self.env, expert_idx)
                expert.load(expert_path)
                self.experts.append(expert)
                expert_idx += 1
            else:
                break
        
        print(f"ğŸ“‚ SB3 MoE Agent loaded: {len(self.experts)} experts")
        
    def merge_clusters_rigorous(self):
        """ì—„ë°€í•œ ìˆ˜í•™ì  ê¸°ì¤€ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„° ë³‘í•©"""
        if hasattr(self, 'dpmm') and hasattr(self.dpmm, 'merge_clusters'):
            return self.dpmm.merge_clusters()  # KL-divergence ê¸°ë°˜ ë³‘í•©
        return None

    def get_dpmm_info(self):
        """DPMM ìƒì„¸ ì •ë³´ ë°˜í™˜"""
        if hasattr(self, 'dpmm'):
            return self.dpmm.get_cluster_info()
        return {'num_clusters': 0, 'cluster_counts': []}

    def get_loss_info(self):
        """SAC ì†ì‹¤ ì •ë³´ ë°˜í™˜"""
        # ê° ì „ë¬¸ê°€ì˜ ìµœê·¼ ì†ì‹¤ ì •ë³´ ìˆ˜ì§‘
        loss_info = {}
        for i, expert in enumerate(self.experts):
            if hasattr(expert, 'last_loss'):
                loss_info[f'expert_{i}'] = expert.last_loss
        return loss_info
    
    # SB3MoEAgent í´ë˜ìŠ¤ì— ì¶”ê°€í•  ë©”ì„œë“œë“¤

# SB3MoEAgent í´ë˜ìŠ¤ì— ì¶”ê°€í•  DPMM ì•ˆì „ ë©”ì„œë“œë“¤

def set_dpmm_params(self, tau_birth=None, tau_merge=None):
    """DPMM íŒŒë¼ë¯¸í„° ì•ˆì „ ì„¤ì •"""
    try:
        if hasattr(self, 'dpmm'):
            if tau_birth is not None:
                if hasattr(self.dpmm, 'tau_birth'):
                    self.dpmm.tau_birth = tau_birth
                elif hasattr(self.dpmm, 'birth_threshold'):
                    self.dpmm.birth_threshold = tau_birth
            
            if tau_merge is not None:
                if hasattr(self.dpmm, 'tau_merge_kl'):
                    self.dpmm.tau_merge_kl = tau_merge
                elif hasattr(self.dpmm, 'cluster_threshold'):
                    self.dpmm.cluster_threshold = tau_merge
                elif hasattr(self.dpmm, 'merge_threshold'):
                    self.dpmm.merge_threshold = tau_merge
            
            print(f"  ğŸ”§ DPMM params set safely: tau_birth={tau_birth}, tau_merge={tau_merge}")
        else:
            print(f"  âš ï¸ No DPMM found in agent")
    except Exception as e:
        print(f"  âš ï¸ DPMM param setting failed: {e}")

def merge_clusters(self, verbose=False):
    """ì•ˆì „í•œ í´ëŸ¬ìŠ¤í„° ë³‘í•©"""
    try:
        if hasattr(self, 'dpmm'):
            if hasattr(self.dpmm, 'merge'):
                self.dpmm.merge(verbose=verbose)
                return True
            elif hasattr(self.dpmm, 'merge_clusters'):
                return self.dpmm.merge_clusters(verbose=verbose)
            else:
                if verbose:
                    print("  âš ï¸ No merge method in DPMM")
                return False
        else:
            if verbose:
                print("  âš ï¸ No DPMM in agent")
            return False
    except Exception as e:
        if verbose:
            print(f"  âš ï¸ Cluster merge failed: {e}")
        return False

def get_info(self):
    """ì•ˆì „í•œ ì—ì´ì „íŠ¸ ì •ë³´ ë°˜í™˜"""
    info = {
        'num_experts': 0,
        'total_buffer_size': 0,
        'dpmm': {
            'num_clusters': 0,
            'cluster_counts': [],
            'total_births': 0,
            'total_merges': 0
        }
    }
    
    try:
        # ì „ë¬¸ê°€ ì •ë³´
        if hasattr(self, 'experts'):
            info['num_experts'] = len(self.experts)
            info['total_buffer_size'] = sum(
                len(getattr(expert, 'replay_buffer', [])) 
                for expert in self.experts
            )
        
        # DPMM ì •ë³´
        if hasattr(self, 'dpmm'):
            if hasattr(self.dpmm, 'get_cluster_info'):
                dpmm_info = self.dpmm.get_cluster_info()
                info['dpmm'].update(dpmm_info)
            elif hasattr(self.dpmm, 'get_num_clusters'):
                info['dpmm']['num_clusters'] = self.dpmm.get_num_clusters()
            elif hasattr(self.dpmm, 'clusters'):
                info['dpmm']['num_clusters'] = len(self.dpmm.clusters)
    
    except Exception as e:
        print(f"  âš ï¸ Info gathering failed: {e}")
    
    return info

def safe_select_action(self, state, instruction_emb, deterministic=False):
    """ì•ˆì „í•œ í–‰ë™ ì„ íƒ (DPMM ì˜¤ë¥˜ ë°©ì§€)"""
    try:
        return self.select_action(state, instruction_emb, deterministic)
    except Exception as e:
        print(f"  âš ï¸ Action selection failed: {e}")
        # ê¸°ë³¸ ëœë¤ í–‰ë™ ë°˜í™˜
        if hasattr(self, 'env') and hasattr(self.env, 'action_space'):
            action = self.env.action_space.sample()
            return action, 0  # ê¸°ë³¸ í´ëŸ¬ìŠ¤í„° ID
        else:
            # ê¸°ë³¸ ì œë¡œ í–‰ë™
            return np.zeros(8), 0  # Ant í™˜ê²½ì˜ ê¸°ë³¸ í–‰ë™ ì°¨ì›

def safe_store_experience(self, state, action, reward, next_state, done, cluster_id):
    """ì•ˆì „í•œ ê²½í—˜ ì €ì¥"""
    try:
        self.store_experience(state, action, reward, next_state, done, cluster_id)
    except Exception as e:
        print(f"  âš ï¸ Experience storage failed: {e}")

def safe_update_experts(self, batch_size=32):
    """ì•ˆì „í•œ ì „ë¬¸ê°€ ì—…ë°ì´íŠ¸"""
    try:
        return self.update_experts(batch_size=batch_size)
    except Exception as e:
        print(f"  âš ï¸ Expert update failed: {e}")
        return None
