import torch
import numpy as np
from typing import Dict, List
from integrated_dpmm_moe_sac import IntegratedDPMMMoESAC

def rigorous_training_loop(env, agent: IntegratedDPMMMoESAC, 
                          instruction_emb, max_episodes: int = 1000,
                          max_steps_per_episode: int = 500,
                          update_frequency: int = 10,
                          merge_frequency: int = 50):
    """ì—„ë°€í•œ Per-Timestep Algorithm êµ¬í˜„"""
    
    print(f"ğŸš€ Starting Rigorous DPMM-MoE-SAC Training")
    print(f"  Max episodes: {max_episodes}")
    print(f"  Max steps per episode: {max_steps_per_episode}")
    print(f"  Update frequency: {update_frequency}")
    print(f"  Merge frequency: {merge_frequency}")
    
    # í†µê³„ ì¶”ì 
    episode_rewards = []
    episode_lengths = []
    cluster_evolution = []
    expert_evolution = []
    
    for episode in range(max_episodes):
        state, _ = env.reset()
        episode_reward = 0
        episode_steps = 0
        episode_cluster_usage = {}
        
        print(f"\nğŸ“ Episode {episode + 1}/{max_episodes}")
        
        for step in range(max_steps_per_episode):
            # ===== Per-Timestep Algorithm =====
            
            # 1. z_t = FusionEncoder(e, s_t)
            # 2. k_t = DPMM.assign(z_t) # birth or assign  
            # 3. if new cluster k_t: init_expert()
            # 4. expert = experts[k_t]
            # 5. a_t, logp = expert.sample_action(s_t)
            action, cluster_id = agent.select_action(
                state=state,
                instruction_emb=instruction_emb,
                deterministic=False
            )
            
            # í´ëŸ¬ìŠ¤í„° ì‚¬ìš© í†µê³„
            if cluster_id not in episode_cluster_usage:
                episode_cluster_usage[cluster_id] = 0
            episode_cluster_usage[cluster_id] += 1
            
            # 6. s_{t+1}, r_t = env.step(a_t)
            next_state, reward, done, info = env.step(action)
            episode_reward += reward
            episode_steps += 1
            
            # 7. expert.replay_buffer.add(s_t, a_t, r_t, s_{t+1}, done)
            agent.store_experience(
                state=state,
                action=action,
                reward=reward,
                next_state=next_state,
                done=done,
                cluster_id=cluster_id
            )
            
            # 8. expert.update() # SAC critic & actor losses
            if step % update_frequency == 0:
                update_losses = agent.update_experts(batch_size=64)
                if step == 0 and update_losses:  # ì²« ìŠ¤í…ì—ì„œë§Œ ì¶œë ¥
                    print(f"  Update losses: {update_losses}")
            
            # 9. if time to merge: DPMM.merge()
            if step % merge_frequency == 0:
                old_cluster_count = agent.dpmm.get_cluster_count()
                agent.merge_clusters()
                new_cluster_count = agent.dpmm.get_cluster_count()
                
                if new_cluster_count != old_cluster_count:
                    print(f"  ğŸ”— Clusters: {old_cluster_count} â†’ {new_cluster_count}")
            
            # ìƒíƒœ ì—…ë°ì´íŠ¸
            state = next_state
            
            # ì—í”¼ì†Œë“œ ì¢…ë£Œ ì¡°ê±´
            if done:
                break
        
        # ì—í”¼ì†Œë“œ í†µê³„
        episode_rewards.append(episode_reward)
        episode_lengths.append(episode_steps)
        
        # í´ëŸ¬ìŠ¤í„°/ì „ë¬¸ê°€ ì§„í™” ì¶”ì 
        evolution = agent.get_cluster_evolution()
        cluster_evolution.append(evolution['current_clusters'])
        expert_evolution.append(len(agent.experts))
        
        # ì—í”¼ì†Œë“œ ìš”ì•½
        print(f"  âœ… Reward: {episode_reward:.2f}, Steps: {episode_steps}")
        print(f"  ğŸ§  Clusters: {evolution['current_clusters']}, Experts: {len(agent.experts)}")
        print(f"  ğŸ“Š Cluster usage: {episode_cluster_usage}")
        
        # ìƒì„¸ í†µê³„ (ë§¤ 10 ì—í”¼ì†Œë“œë§ˆë‹¤)
        if (episode + 1) % 10 == 0:
            comprehensive_stats = agent.get_comprehensive_statistics()
            print(f"\nğŸ“ˆ Episode {episode + 1} Comprehensive Stats:")
            print(f"  DPMM: {comprehensive_stats['dpmm']['num_clusters']} clusters")
            print(f"  Total births: {comprehensive_stats['dpmm']['total_births']}")
            print(f"  Total merges: {comprehensive_stats['dpmm']['total_merges']}")
            print(f"  Expert usage: {comprehensive_stats['expert_usage']}")
            
            # ìµœê·¼ 10 ì—í”¼ì†Œë“œ í‰ê·  ì„±ëŠ¥
            recent_rewards = episode_rewards[-10:]
            avg_reward = np.mean(recent_rewards)
            print(f"  Recent avg reward: {avg_reward:.2f}")
    
    # ìµœì¢… í†µê³„ ë° ì‹œê°í™”
    final_stats = {
        'episode_rewards': episode_rewards,
        'episode_lengths': episode_lengths,
        'cluster_evolution': cluster_evolution,
        'expert_evolution': expert_evolution,
        'final_comprehensive_stats': agent.get_comprehensive_statistics()
    }
    
    print(f"\nğŸ¯ Training Completed!")
    print(f"  Total episodes: {len(episode_rewards)}")
    print(f"  Average reward: {np.mean(episode_rewards):.2f}")
    print(f"  Final clusters: {cluster_evolution[-1]}")
    print(f"  Final experts: {expert_evolution[-1]}")
    
    return final_stats

def visualize_cluster_evolution(stats: Dict):
    """í´ëŸ¬ìŠ¤í„° ì§„í™” ì‹œê°í™”"""
    try:
        import matplotlib.pyplot as plt
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        
        # 1. ì—í”¼ì†Œë“œë³„ ë³´ìƒ
        axes[0, 0].plot(stats['episode_rewards'])
        axes[0, 0].set_title('Episode Rewards')
        axes[0, 0].set_xlabel('Episode')
        axes[0, 0].set_ylabel('Reward')
        
        # 2. í´ëŸ¬ìŠ¤í„° ìˆ˜ ì§„í™” (K_t)
        axes[0, 1].plot(stats['cluster_evolution'], label='Clusters', color='blue')
        axes[0, 1].plot(stats['expert_evolution'], label='Experts', color='red')
        axes[0, 1].set_title('Dynamic Behavior: K_t Evolution')
        axes[0, 1].set_xlabel('Episode')
        axes[0, 1].set_ylabel('Count')
        axes[0, 1].legend()
        
        # 3. ì—í”¼ì†Œë“œ ê¸¸ì´
        axes[1, 0].plot(stats['episode_lengths'])
        axes[1, 0].set_title('Episode Lengths')
        axes[1, 0].set_xlabel('Episode')
        axes[1, 0].set_ylabel('Steps')
        
        # 4. ì „ë¬¸ê°€ ì‚¬ìš© ë¶„í¬
        final_stats = stats['final_comprehensive_stats']
        expert_usage = final_stats['expert_usage']
        if expert_usage:
            experts = list(expert_usage.keys())
            usage_counts = list(expert_usage.values())
            axes[1, 1].bar(experts, usage_counts)
            axes[1, 1].set_title('Expert Usage Distribution')
            axes[1, 1].set_xlabel('Expert ID')
            axes[1, 1].set_ylabel('Usage Count')
        
        plt.tight_layout()
        plt.savefig('dpmm_moe_sac_evolution.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        print("ğŸ“Š Visualization saved as 'dpmm_moe_sac_evolution.png'")
        
    except ImportError:
        print("âš ï¸ matplotlib not available for visualization")

def analyze_dpmm_behavior(agent: IntegratedDPMMMoESAC):
    """DPMM í–‰ë™ ë¶„ì„"""
    stats = agent.get_comprehensive_statistics()
    
    print(f"\nğŸ”¬ DPMM Behavior Analysis:")
    print(f"=" * 50)
    
    # í´ëŸ¬ìŠ¤í„° ì •ë³´
    dpmm_stats = stats['dpmm']
    print(f"ğŸ“Š Cluster Statistics:")
    print(f"  Total clusters: {dpmm_stats['num_clusters']}")
    print(f"  Cluster sizes: {dpmm_stats['cluster_sizes']}")
    print(f"  Total births: {dpmm_stats['total_births']}")
    print(f"  Total merges: {dpmm_stats['total_merges']}")
    
    # í´ëŸ¬ìŠ¤í„° í‰ê· ë“¤
    print(f"\nğŸ¯ Cluster Centers (Î¼_k):")
    for cluster_id, mean in dpmm_stats['cluster_means'].items():
        print(f"  Cluster {cluster_id}: Î¼ = {np.array(mean)}")
    
    # í´ëŸ¬ìŠ¤í„° ë¶„ì‚°ë“¤
    print(f"\nğŸ“ˆ Cluster Variances (ÏƒÂ²_k):")
    for cluster_id, var in dpmm_stats['cluster_variances'].items():
        print(f"  Cluster {cluster_id}: ÏƒÂ² = {var:.4f}")
    
    # Birth/Merge ì´ë²¤íŠ¸ ë¶„ì„
    birth_events = agent.dpmm.birth_events
    merge_events = agent.dpmm.merge_events
    
    print(f"\nğŸ£ Birth Events Analysis:")
    for i, event in enumerate(birth_events[-5:]):  # ìµœê·¼ 5ê°œë§Œ
        print(f"  Birth {i}: Cluster {event['cluster_id']} at timestep {event['timestep']}")
    
    print(f"\nğŸ”— Merge Events Analysis:")
    for i, event in enumerate(merge_events[-3:]):  # ìµœê·¼ 3ê°œë§Œ
        print(f"  Merge {i}: {event['old_clusters']} â†’ {event['new_cluster']} at timestep {event['timestep']}")
    
    # ì „ë¬¸ê°€ ì„±ëŠ¥ ë¶„ì„
    print(f"\nğŸ¤– Expert Performance Analysis:")
    for expert_id, expert_stats in stats['experts'].items():
        print(f"  {expert_id}:")
        print(f"    Updates: {expert_stats['update_count']}")
        print(f"    Buffer size: {expert_stats['buffer_size']}")
        print(f"    Current Î±: {expert_stats['current_alpha']:.4f}")
        
        recent_losses = expert_stats['recent_losses']
        if recent_losses.get('actor_loss'):
            avg_actor_loss = np.mean(recent_losses['actor_loss'])
            avg_critic_loss = np.mean(recent_losses['critic1_loss'])
            print(f"    Recent avg actor loss: {avg_actor_loss:.4f}")
            print(f"    Recent avg critic loss: {avg_critic_loss:.4f}")

def mathematical_verification(agent: IntegratedDPMMMoESAC):
    """ìˆ˜í•™ì  ê³µì‹ ê²€ì¦"""
    print(f"\nğŸ”¬ Mathematical Verification:")
    print(f"=" * 50)
    
    # DPMM ê³µì‹ ê²€ì¦
    print(f"ğŸ“ DPMM Formulas:")
    for cluster_id, cluster in agent.dpmm.clusters.items():
        print(f"  Cluster {cluster_id}:")
        print(f"    Î¼_k = Î£x_i / N_k")
        print(f"    Current: Î¼ = {cluster.mu}")
        print(f"    N_k = {cluster.N}")
        
        # ì˜¨ë¼ì¸ ì—…ë°ì´íŠ¸ ê³µì‹ í™•ì¸
        expected_mu = cluster.sum_x / cluster.N
        mu_diff = np.linalg.norm(cluster.mu - expected_mu)
        print(f"    Online update error: ||Î¼_computed - Î¼_expected|| = {mu_diff:.8f}")
    
    # SAC ê³µì‹ í™•ì¸
    print(f"\nğŸ¯ SAC Formulas:")
    for expert in agent.experts[:2]:  # ì²˜ìŒ 2ê°œ ì „ë¬¸ê°€ë§Œ
        print(f"  Expert {expert.expert_id}:")
        print(f"    Target entropy: H_target = -dim(A) = {expert.target_entropy}")
        print(f"    Current Î±: {expert.alpha.item():.4f}")
        print(f"    Î³ (discount): {expert.gamma}")
        print(f"    Ï„ (soft update): {expert.tau}")
    
    # í´ëŸ¬ìŠ¤í„° ì§„í™” ê³µì‹: K_{t+1} = K_t + 1_{birth} - 1_{merge}
    evolution = agent.get_cluster_evolution()
    print(f"\nğŸ“ˆ Cluster Evolution Formula: K_{{t+1}} = K_t + 1_{{birth}} - 1_{{merge}}")
    print(f"  Current K_t: {evolution['current_clusters']}")
    print(f"  Total births: {len(agent.dpmm.birth_events)}")
    print(f"  Total merges: {len(agent.dpmm.merge_events)}")
    
    # ì´ë¡ ì  vs ì‹¤ì œ í´ëŸ¬ìŠ¤í„° ìˆ˜
    theoretical_K = len(agent.dpmm.birth_events) - len(agent.dpmm.merge_events)
    actual_K = evolution['current_clusters']
    print(f"  Theoretical K: {theoretical_K}")
    print(f"  Actual K: {actual_K}")
    print(f"  Difference: {abs(theoretical_K - actual_K)}")