#!/usr/bin/env python3
"""
RTX 4060 ìµœì í™” í†µí•© KL-DPMM MoE-SAC í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
"""

import argparse
import torch
import numpy as np
import yaml
import os
import gc
from isaaclab.app import AppLauncher

def main():
    parser = argparse.ArgumentParser(description="RTX 4060 Integrated KL-DPMM MoE-SAC Training")
    parser.add_argument("--tasks", type=str, default="tasks.yaml")
    parser.add_argument("--save_dir", type=str, default="./rtx4060_outputs")
    parser.add_argument("--num_envs", type=int, default=64)  # RTX 4060ì— ë§ê²Œ ì¶•ì†Œ
    parser.add_argument("--episodes_per_task", type=int, default=50)
    parser.add_argument("--max_steps", type=int, default=300)
    parser.add_argument("--tau_birth", type=float, default=1e-3)
    parser.add_argument("--tau_merge_kl", type=float, default=0.1)
    parser.add_argument("--batch_size", type=int, default=32)
    parser.add_argument("--update_freq", type=int, default=10)
    parser.add_argument("--merge_freq", type=int, default=15)
    parser.add_argument("--checkpoint_freq", type=int, default=25)
    AppLauncher.add_app_launcher_args(parser)
    args = parser.parse_args()

    # RTX 4060 ë©”ëª¨ë¦¬ ìµœì í™” ì„¤ì •
    torch.backends.cudnn.benchmark = False  # ë©”ëª¨ë¦¬ ì ˆì•½
    torch.backends.cudnn.deterministic = True
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        # ë©”ëª¨ë¦¬ ë¶„í•  ìµœì í™”
        os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'

    app = AppLauncher(vars(args))
    sim = app.app

    # í•„ìš”í•œ ëª¨ë“ˆë“¤ import
    from ant_push_env import IsaacAntPushEnv
    from integrated_kl_dpmm_moe_sac import IntegratedKLDPMMMoESAC

    print(f"ğŸš€ RTX 4060 Optimized Integrated Training Started")
    print(f"  Batch size: {args.batch_size}")
    print(f"  Episodes per task: {args.episodes_per_task}")
    print(f"  Max steps: {args.max_steps}")
    print(f"  Birth threshold: {args.tau_birth}")
    print(f"  KL merge threshold: {args.tau_merge_kl}")

    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(args.save_dir, exist_ok=True)

    # íƒœìŠ¤í¬ ë¡œë“œ
    tasks = yaml.safe_load(open(args.tasks))
    
    # í†µí•© ì—ì´ì „íŠ¸ ì´ˆê¸°í™” (ì•„ì§ í•˜ì§€ ì•ŠìŒ)
    agent = None
    
    # ì „ì²´ í•™ìŠµ í†µê³„
    all_stats = {
        'task_names': [],
        'episode_rewards': [],
        'cluster_evolution': [],
        'expert_evolution': [],
        'merge_events': [],
        'memory_usage': []
    }

    try:
        # íƒœìŠ¤í¬ë³„ í•™ìŠµ
        for task_idx, task in enumerate(tasks):
            print(f"\n{'='*60}")
            print(f"ğŸ¯ Task {task_idx + 1}/{len(tasks)}: {task['name']}")
            print(f"ğŸ“ Instruction: {task['instruction']}")
            print(f"{'='*60}")
            
            # í™˜ê²½ ìƒì„±
            env = IsaacAntPushEnv(custom_cfg=task['env_cfg'], num_envs=args.num_envs)
            
            # ì´ˆê¸° ìƒíƒœë¡œ ì°¨ì› í™•ì¸
            state, _ = env.reset()
            state_dim = state.shape[0]
            action_dim = env.action_space.shape[1] if len(env.action_space.shape) == 2 else env.action_space.shape[0]
            
            print(f"ğŸ”§ Environment Setup:")
            print(f"  State dim: {state_dim}")
            print(f"  Action dim: {action_dim}")
            
            # ì—ì´ì „íŠ¸ ì´ˆê¸°í™” (ì²« ë²ˆì§¸ íƒœìŠ¤í¬ì—ì„œë§Œ)
            if agent is None:
                agent = IntegratedKLDPMMMoESAC(
                    state_dim=state_dim,
                    action_dim=action_dim,
                    instr_dim=384,  # sentence transformer ì¶œë ¥ ì°¨ì›
                    latent_dim=32,
                    tau_birth=args.tau_birth,
                    tau_merge_kl=args.tau_merge_kl,
                    device="cuda" if torch.cuda.is_available() else "cpu"
                )
                print(f"ğŸ¤– Agent initialized")
            
            # íƒœìŠ¤í¬ë³„ í†µê³„
            task_stats = {
                'episode_rewards': [],
                'cluster_counts': [],
                'expert_counts': [],
                'merge_events': []
            }
            
            # ì—í”¼ì†Œë“œ í•™ìŠµ
            for episode in range(args.episodes_per_task):
                print(f"\n--- Episode {episode + 1}/{args.episodes_per_task} ---")
                
                # í™˜ê²½ ë¦¬ì…‹
                state, _ = env.reset()
                episode_reward = 0
                step_count = 0
                episode_experiences = []
                
                while step_count < args.max_steps:
                    # í–‰ë™ ì„ íƒ
                    action, cluster_id = agent.select_action(
                        state, 
                        task['instruction'],
                        deterministic=False
                    )
                    
                    if step_count == 0:
                        print(f"  ğŸ¯ Assigned to cluster/expert: {cluster_id}")
                    
                    # í™˜ê²½ ìŠ¤í…
                    try:
                        next_state, reward, done, info = env.step(action)
                        episode_reward += reward
                        
                        # ê²½í—˜ ì €ì¥
                        agent.store_experience(
                            state, action, reward, next_state, done,
                            task['instruction'], cluster_id
                        )
                        
                        state = next_state
                        step_count += 1
                        
                        if done:
                            break
                            
                    except Exception as e:
                        print(f"  âš ï¸ Environment step error: {e}")
                        break
                
                # ì£¼ê¸°ì  ì—…ë°ì´íŠ¸
                if episode % args.update_freq == 0:
                    update_info = agent.update_experts(batch_size=args.batch_size)
                    if episode % (args.update_freq * 2) == 0:
                        print(f"  ğŸ“ˆ Updated {update_info['updated_experts']}/{update_info['total_experts']} experts")
                
                # KL ê¸°ë°˜ ë³‘í•©
                if episode % args.merge_freq == 0:
                    merged = agent.merge_clusters(verbose=(episode % (args.merge_freq * 2) == 0))
                    if merged:
                        task_stats['merge_events'].append(episode)
                
                # í†µê³„ ìˆ˜ì§‘
                stats = agent.get_statistics()
                task_stats['episode_rewards'].append(episode_reward)
                task_stats['cluster_counts'].append(stats['dpmm']['num_clusters'])
                task_stats['expert_counts'].append(stats['experts']['total_experts'])
                
                # ë©”ëª¨ë¦¬ ì •ë¦¬ (RTX 4060 ìµœì í™”)
                if episode % 10 == 0:
                    torch.cuda.empty_cache()
                    gc.collect()
                
                # ì£¼ê¸°ì  ì¶œë ¥
                if episode % 10 == 0 or episode == args.episodes_per_task - 1:
                    print(f"  ğŸ“Š Episode {episode + 1} Summary:")
                    print(f"    Reward: {episode_reward:.2f}")
                    print(f"    Steps: {step_count}")
                    print(f"    Clusters: {stats['dpmm']['num_clusters']}")
                    print(f"    Experts: {stats['experts']['total_experts']}")
                    print(f"    Total births: {stats['dpmm']['total_births']}")
                    print(f"    Total KL-merges: {stats['dpmm']['total_merges']}")
                    
                    # GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
                    if torch.cuda.is_available():
                        memory_used = torch.cuda.memory_allocated() / 1024**2  # MB
                        print(f"    GPU Memory: {memory_used:.1f} MB")
                        all_stats['memory_usage'].append(memory_used)
                    
                    # ìµœê·¼ í‰ê·  ë³´ìƒ
                    recent_rewards = task_stats['episode_rewards'][-10:]
                    if recent_rewards:
                        print(f"    Recent avg reward: {np.mean(recent_rewards):.2f}")
            
            # íƒœìŠ¤í¬ ì™„ë£Œ í›„ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
            if (task_idx + 1) % args.checkpoint_freq == 0:
                checkpoint_path = os.path.join(args.save_dir, f"checkpoint_task_{task_idx + 1}.pt")
                agent.save_checkpoint(checkpoint_path)
            
            # ì „ì²´ í†µê³„ì— ì¶”ê°€
            all_stats['task_names'].append(task['name'])
            all_stats['episode_rewards'].extend(task_stats['episode_rewards'])
            all_stats['cluster_evolution'].extend(task_stats['cluster_counts'])
            all_stats['expert_evolution'].extend(task_stats['expert_counts'])
            all_stats['merge_events'].extend(task_stats['merge_events'])
            
            # íƒœìŠ¤í¬ ìš”ì•½
            print(f"\nğŸ Task '{task['name']}' completed!")
            print(f"  Average reward: {np.mean(task_stats['episode_rewards']):.2f}")
            print(f"  Final clusters: {task_stats['cluster_counts'][-1]}")
            print(f"  Final experts: {task_stats['expert_counts'][-1]}")
            print(f"  KL-merge events: {len(task_stats['merge_events'])}")
            
            env.close()
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            torch.cuda.empty_cache()
            gc.collect()
        
        # ìµœì¢… ì²´í¬í¬ì¸íŠ¸ ì €ì¥
        final_checkpoint_path = os.path.join(args.save_dir, "final_checkpoint.pt")
        agent.save_checkpoint(final_checkpoint_path)
        
        # í•™ìŠµ í†µê³„ ì €ì¥
        stats_path = os.path.join(args.save_dir, "training_stats.npz")
        np.savez(stats_path, **all_stats)
        
        # ìµœì¢… ë¶„ì„ ë° ì‹œê°í™”
        print(f"\nğŸ‰ All tasks completed!")
        analyze_training_results(all_stats, args.save_dir)
        
    except Exception as e:
        print(f"âŒ Training failed with error: {e}")
        import traceback
        traceback.print_exc()
        
        # ì—ëŸ¬ ë°œìƒ ì‹œì—ë„ ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì‹œë„
        if agent is not None:
            try:
                emergency_path = os.path.join(args.save_dir, "emergency_checkpoint.pt")
                agent.save_checkpoint(emergency_path)
                print(f"ğŸ†˜ Emergency checkpoint saved to {emergency_path}")
            except:
                pass
    
    finally:
        sim.close()
        torch.cuda.empty_cache()

def analyze_training_results(stats: dict, save_dir: str):
    """í•™ìŠµ ê²°ê³¼ ë¶„ì„ ë° ì‹œê°í™”"""
    print(f"\nğŸ”¬ TRAINING ANALYSIS")
    print(f"="*50)
    
    # ê¸°ë³¸ í†µê³„
    total_episodes = len(stats['episode_rewards'])
    avg_reward = np.mean(stats['episode_rewards'])
    final_clusters = stats['cluster_evolution'][-1] if stats['cluster_evolution'] else 0
    final_experts = stats['expert_evolution'][-1] if stats['expert_evolution'] else 0
    total_merges = len(stats['merge_events'])
    
    print(f"ğŸ“Š Basic Statistics:")
    print(f"  Total episodes: {total_episodes}")
    print(f"  Average reward: {avg_reward:.3f}")
    print(f"  Final clusters: {final_clusters}")
    print(f"  Final experts: {final_experts}")
    print(f"  Total KL-merges: {total_merges}")
    
    if stats['memory_usage']:
        avg_memory = np.mean(stats['memory_usage'])
        max_memory = np.max(stats['memory_usage'])
        print(f"  Average GPU memory: {avg_memory:.1f} MB")
        print(f"  Peak GPU memory: {max_memory:.1f} MB")
    
    # í•™ìŠµ ê³¡ì„  ë¶„ì„
    if len(stats['episode_rewards']) > 10:
        early_rewards = np.mean(stats['episode_rewards'][:10])
        late_rewards = np.mean(stats['episode_rewards'][-10:])
        improvement = late_rewards - early_rewards
        print(f"  Learning improvement: {improvement:.3f}")
        print(f"  Early avg reward: {early_rewards:.3f}")
        print(f"  Late avg reward: {late_rewards:.3f}")
    
    # í´ëŸ¬ìŠ¤í„° ì§„í™” ë¶„ì„
    if stats['cluster_evolution']:
        max_clusters = np.max(stats['cluster_evolution'])
        cluster_stability = np.std(stats['cluster_evolution'][-20:]) if len(stats['cluster_evolution']) > 20 else 0
        print(f"  Max clusters reached: {max_clusters}")
        print(f"  Recent cluster stability (std): {cluster_stability:.2f}")
    
    # ê°„ë‹¨í•œ í”Œë¡¯ ìƒì„± (matplotlib ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
    try:
        import matplotlib.pyplot as plt
        
        fig, axes = plt.subplots(2, 2, figsize=(12, 8))
        
        # ë³´ìƒ ê³¡ì„ 
        axes[0, 0].plot(stats['episode_rewards'])
        axes[0, 0].set_title('Episode Rewards')
        axes[0, 0].set_xlabel('Episode')
        axes[0, 0].set_ylabel('Reward')
        
        # í´ëŸ¬ìŠ¤í„° ì§„í™”
        if stats['cluster_evolution']:
            axes[0, 1].plot(stats['cluster_evolution'])
            axes[0, 1].set_title('Cluster Evolution')
            axes[0, 1].set_xlabel('Episode')
            axes[0, 1].set_ylabel('Number of Clusters')
        
        # ì „ë¬¸ê°€ ì§„í™”
        if stats['expert_evolution']:
            axes[1, 0].plot(stats['expert_evolution'])
            axes[1, 0].set_title('Expert Evolution')
            axes[1, 0].set_xlabel('Episode')
            axes[1, 0].set_ylabel('Number of Experts')
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
        if stats['memory_usage']:
            axes[1, 1].plot(stats['memory_usage'])
            axes[1, 1].set_title('GPU Memory Usage')
            axes[1, 1].set_xlabel('Checkpoint')
            axes[1, 1].set_ylabel('Memory (MB)')
        
        plt.tight_layout()
        plot_path = os.path.join(save_dir, "training_analysis.png")
        plt.savefig(plot_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"ğŸ“ˆ Training plots saved to {plot_path}")
        
    except ImportError:
        print("ğŸ“ˆ Matplotlib not available, skipping plots")
    except Exception as e:
        print(f"ğŸ“ˆ Plot generation failed: {e}")

if __name__ == "__main__":
    main()
