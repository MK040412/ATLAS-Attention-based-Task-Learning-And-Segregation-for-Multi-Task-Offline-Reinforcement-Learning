import argparse
import torch
import yaml
import numpy as np
import time
from isaaclab.app import AppLauncher

def main():
    parser = argparse.ArgumentParser(description="Working Ant MoE Training")
    parser.add_argument("--tasks", type=str, default="working_tasks.yaml")
    parser.add_argument("--num_envs", type=int, default=1)
    parser.add_argument("--episodes", type=int, default=3)
    parser.add_argument("--max_steps", type=int, default=100)
    AppLauncher.add_app_launcher_args(parser)
    args = parser.parse_args()

    app = AppLauncher(vars(args))
    sim = app.app

    try:
        from working_ant_push_env import WorkingAntPushEnv
        from working_moe_agent import WorkingMoEAgent, WorkingLanguageProcessor
        
        print("ğŸš€ Starting Working Ant MoE Training")
        
        # ì–¸ì–´ í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
        lang_processor = WorkingLanguageProcessor()
        
        # íƒœìŠ¤í¬ ì •ì˜ (YAML íŒŒì¼ì´ ì—†ì–´ë„ ì‘ë™)
        tasks = [
            {
                'name': 'basic_push',
                'instruction': 'Push the cube to the target location',
                'env_cfg': {
                    'cube_position': [2.0, 0.0, 0.1],
                    'goal_position': [3.0, 0.0, 0.1]
                },
                'episodes': args.episodes
            },
            {
                'name': 'long_push',
                'instruction': 'Move the cube far to the target location',
                'env_cfg': {
                    'cube_position': [1.0, 0.0, 0.1],
                    'goal_position': [4.0, 0.0, 0.1]
                },
                'episodes': args.episodes
            }
        ]
        
        # MoE ì—ì´ì „íŠ¸ ì´ˆê¸°í™” (í™˜ê²½ ìƒì„± í›„)
        moe_agent = None
        
        # ê° íƒœìŠ¤í¬ ì‹¤í–‰
        for task_idx, task in enumerate(tasks):
            print(f"\n{'='*60}")
            print(f"ğŸ“‹ Task {task_idx+1}/{len(tasks)}: {task['name']}")
            print(f"ğŸ’¬ Instruction: {task['instruction']}")
            print(f"{'='*60}")
            
            # í™˜ê²½ ìƒì„±
            print("ğŸ—ï¸ Creating environment...")
            env = WorkingAntPushEnv(custom_cfg=task['env_cfg'], num_envs=args.num_envs)
            
            # ì²« ë²ˆì§¸ íƒœìŠ¤í¬ì—ì„œ MoE ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
            if moe_agent is None:
                state, _ = env.reset()
                state_dim = len(state)
                action_dim = env.get_action_dim()
                
                moe_agent = WorkingMoEAgent(
                    state_dim=state_dim,
                    action_dim=action_dim
                )
            
            # ì§€ì‹œì‚¬í•­ ì„ë² ë”©
            instruction_emb = lang_processor.encode(task['instruction'])
            
            # ì—í”¼ì†Œë“œ ì‹¤í–‰
            task_start_time = time.time()
            total_steps = 0
            total_reward = 0
            
            for episode in range(task['episodes']):
                print(f"\n--- Episode {episode + 1}/{task['episodes']} ---")
                
                state, _ = env.reset()
                episode_reward = 0
                episode_steps = 0
                episode_losses = []
                used_experts = set()
                
                for step in range(args.max_steps):
                    # í–‰ë™ ì„ íƒ
                    action, expert_id = moe_agent.select_action(
                        state, instruction_emb, deterministic=False
                    )
                    used_experts.add(expert_id)
                    
                    # í™˜ê²½ ìŠ¤í…
                    next_state, reward, done, info = env.step(action)
                    
                    # ê²½í—˜ ì €ì¥ ë° í•™ìŠµ
                    loss_info = moe_agent.update_expert(
                        expert_id, state, action, reward, next_state, done
                    )
                    if loss_info:
                        episode_losses.append(loss_info)
                    
                    episode_reward += reward
                    episode_steps += 1
                    state = next_state
                    
                    if done:
                        break
                
                total_steps += episode_steps
                total_reward += episode_reward
                
                # ì—í”¼ì†Œë“œ ê²°ê³¼ ì¶œë ¥
                avg_loss = np.mean([l['total_loss'] for l in episode_losses]) if episode_losses else 0.0
                print(f"âœ“ Episode {episode + 1} completed:")
                print(f"    Steps: {episode_steps}, Time: {time.time() - task_start_time:.1f}s")
                print(f"    Reward: {episode_reward:.3f}, Avg Loss: {avg_loss:.6f}")
                print(f"    Experts used: {len(used_experts)}")
            
            # íƒœìŠ¤í¬ ì™„ë£Œ í†µê³„
            task_time = time.time() - task_start_time
            avg_reward = total_reward / task['episodes']
            stats = moe_agent.get_stats()
            
            print(f"\nğŸ¯ Task '{task['name']}' completed!")
            print(f"  Time: {task_time:.1f}s")
            print(f"  Episodes: {task['episodes']}")
            print(f"  Total steps: {total_steps}")
            print(f"  Average reward: {avg_reward:.3f}")
            print(f"  Total clusters: {stats['num_clusters']}")
            print(f"  Expert usage: {stats['expert_usage']}")
            
            # í™˜ê²½ ì •ë¦¬
            print("ğŸ”„ Closing environment safely...")
            env.close()
            print("âœ“ Environment closed")
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            torch.cuda.empty_cache() if torch.cuda.is_available() else None
            print("âœ“ Memory cleaned up")
            
            # ì‹œìŠ¤í…œ ì•ˆì •í™” ëŒ€ê¸°
            if task_idx < len(tasks) - 1:
                print("â³ Waiting for system stabilization...")
                time.sleep(2)
        
        # ìµœì¢… í†µê³„
        final_stats = moe_agent.get_stats()
        print(f"\nğŸ† Training Completed!")
        print(f"  Total experts created: {final_stats['num_experts']}")
        print(f"  Total clusters discovered: {final_stats['num_clusters']}")
        print(f"  Final expert usage: {final_stats['expert_usage']}")
        
    except Exception as e:
        print(f"âŒ Training failed: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        print("\nğŸ”„ Shutting down simulation...")
        try:
            sim.close()
            print("âœ… Simulation closed successfully")
        except:
            print("âš ï¸ Simulation close had issues, but continuing...")

if __name__ == "__main__":
    main()