import argparse
import torch
from isaaclab.app import AppLauncher

def main():
    parser = argparse.ArgumentParser(description="Ultimate Fixed Ant MoE Training v4")
    parser.add_argument("--tasks", type=str, default="simple_test_tasks.yaml")
    parser.add_argument("--save_dir", type=str, default="./outputs")
    parser.add_argument("--num_envs", type=int, default=4)
    parser.add_argument("--max_episodes", type=int, default=2)
    parser.add_argument("--max_steps", type=int, default=50)
    parser.add_argument("--debug", action="store_true")
    
    AppLauncher.add_app_launcher_args(parser)
    args = parser.parse_args()

    print("ğŸš€ Starting Ultimate Fixed Training v4...")
    print(f"ğŸ“‹ Configuration:")
    print(f"  Tasks file: {args.tasks}")
    print(f"  Save directory: {args.save_dir}")
    print(f"  Number of environments: {args.num_envs}")
    print(f"  Max episodes per task: {args.max_episodes}")
    print(f"  Max steps per episode: {args.max_steps}")

    app = AppLauncher(vars(args))
    sim = app.app

    try:
        import yaml
        import numpy as np
        import os
        import time
        from pathlib import Path
        
        from ant_push_env_final_fix import IsaacAntPushEnv
        from config import CONFIG
        from language_processor import LanguageProcessor
        from robust_dpmm_detector import RobustDPMMOODDetector
        from dimension_aware_fusion_fixed import DimensionAwareFusion
        from memory_optimized_sac_ultra_safe import DimensionExactSACExpert

        os.makedirs(args.save_dir, exist_ok=True)

        try:
            with open(args.tasks, 'r') as f:
                tasks = yaml.safe_load(f)
            print(f"âœ“ Loaded {len(tasks)} tasks from {args.tasks}")
        except Exception as e:
            print(f"âŒ Failed to load tasks: {e}")
            return

        print("\nğŸ”§ Initializing components...")
        
        lang = LanguageProcessor(device=CONFIG.device)
        print("âœ“ Language processor initialized")
        
        dpmm = RobustDPMMOODDetector(latent_dim=CONFIG.latent_dim)
        print("âœ“ DPMM detector initialized")
        
        fusion = None
        experts = []
        
        def init_expert(state_dim, action_dim):
            print(f"  ğŸ§  Creating new expert {len(experts)}")
            expert = DimensionExactSACExpert(
                state_dim=state_dim, 
                action_dim=action_dim, 
                device=CONFIG.device,
                hidden_dim=CONFIG.hidden_dim
            )
            experts.append(expert)
            return expert

        def safe_cleanup():
            try:
                import gc
                gc.collect()
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                time.sleep(0.5)
                print("âœ“ Memory cleaned up")
            except Exception as e:
                print(f"Warning: Cleanup failed: {e}")

        def safe_tensor_conversion(data, device):
            """ì•ˆì „í•œ í…ì„œ ë³€í™˜ í•¨ìˆ˜"""
            try:
                if torch.is_tensor(data):
                    return data.to(device)
                elif isinstance(data, np.ndarray):
                    return torch.from_numpy(data).float().to(device)
                else:
                    return torch.tensor(data, dtype=torch.float32, device=device)
            except Exception as e:
                print(f"Warning: Tensor conversion failed: {e}")
                return torch.zeros(1, device=device, dtype=torch.float32)

        print(f"\n{'='*60}")
        print("ğŸ¯ Starting Training Loop")
        print(f"{'='*60}")
        
        global_stats = {
            'total_episodes': 0,
            'total_steps': 0,
            'total_rewards': [],
            'task_results': {}
        }

        for task_idx, task in enumerate(tasks):
            print(f"\n{'='*50}")
            print(f"ğŸ“‹ Task {task_idx + 1}/{len(tasks)}: {task['name']}")
            print(f"ğŸ’¬ Instruction: {task['instruction']}")
            print(f"{'='*50}")
            
            task_start_time = time.time()
            env = None
            
            try:
                print("ğŸ—ï¸ Creating environment...")
                env = IsaacAntPushEnv(
                    custom_cfg=task['env_cfg'], 
                    num_envs=args.num_envs
                )
                
                print("ğŸ”„ Getting environment dimensions...")
                state, _ = env.reset()
                state_dim = len(state)
                action_dim = env.get_action_dim()
                
                print(f"ğŸ“ Environment dimensions:")
                print(f"  State dim: {state_dim}")
                print(f"  Action dim: {action_dim}")
                
                if fusion is None:
                    print("ğŸ”— Initializing fusion model...")
                    fusion = DimensionAwareFusion(
                        instr_dim=CONFIG.instr_emb_dim,
                        state_dim=state_dim,
                        latent_dim=CONFIG.latent_dim
                    ).to(CONFIG.device)
                    print("âœ“ Fusion model initialized")
                
                print("ğŸ’­ Encoding instruction...")
                instr_emb = lang.encode(task['instruction'])
                print(f"âœ“ Instruction embedded: {instr_emb.shape}")
                
                task_stats = {
                    'episodes': 0,
                    'total_steps': 0,
                    'total_reward': 0.0,
                    'episode_rewards': [],
                    'expert_usage': {},
                    'errors': []
                }
                
                for episode in range(task['episodes']):
                    print(f"\n--- Episode {episode + 1}/{task['episodes']} ---")
                    
                    episode_start_time = time.time()
                    episode_reward = 0.0
                    episode_steps = 0
                    episode_losses = []
                    
                    state, _ = env.reset()
                    done = False
                    
                    while not done and episode_steps < args.max_steps:
                        try:
                            # ì•ˆì „í•œ í…ì„œ ë³€í™˜
                            with torch.no_grad():
                                state_tensor = safe_tensor_conversion(state, CONFIG.device)
                                if state_tensor.dim() == 1:
                                    state_tensor = state_tensor.unsqueeze(0)
                                
                                instr_tensor = safe_tensor_conversion(instr_emb, CONFIG.device)
                                if instr_tensor.dim() == 1:
                                    instr_tensor = instr_tensor.unsqueeze(0)
                                
                                # ìœµí•©ëœ íŠ¹ì§• ì¶”ì¶œ
                                z = fusion(instr_tensor, state_tensor)
                                if z.dim() > 1:
                                    z = z.squeeze(0)
                            
                            # í´ëŸ¬ìŠ¤í„° í• ë‹¹
                            z_numpy = z.detach().cpu().numpy()
                            cluster_id = dpmm.assign(z_numpy)
                            
                            # ì „ë¬¸ê°€ ìƒì„± (í•„ìš”ì‹œ)
                            if cluster_id >= len(experts):
                                init_expert(state_dim, action_dim)
                            
                            # í–‰ë™ ì„ íƒ
                            expert = experts[cluster_id]
                            action = expert.select_action(state, deterministic=False)
                            
                            # í™˜ê²½ ìŠ¤í…
                            next_state, reward, done, info = env.step(action)
                            
                            # ê²½í—˜ ì €ì¥
                            expert.replay_buffer.add(state, action, reward, next_state, done)
                            
                            # í•™ìŠµ (ì£¼ê¸°ì ìœ¼ë¡œ)
                            if episode_steps % 10 == 0 and len(expert.replay_buffer) > 32:
                                loss_info = expert.update(batch_size=32)
                                if loss_info:
                                    episode_losses.append(loss_info)
                            
                            # í†µê³„ ì—…ë°ì´íŠ¸
                            episode_reward += reward
                            episode_steps += 1
                            
                            if cluster_id not in task_stats['expert_usage']:
                                task_stats['expert_usage'][cluster_id] = 0
                            task_stats['expert_usage'][cluster_id] += 1
                            
                            # ë””ë²„ê·¸ ì¶œë ¥ (ì£¼ê¸°ì ìœ¼ë¡œ)
                            if args.debug and episode_steps % 25 == 0:
                                print(f"    Step {episode_steps}: reward={reward:.3f}, expert={cluster_id}")
                            
                            state = next_state
                            
                        except Exception as step_error:
                            print(f"âš ï¸ Step error: {step_error}")
                            task_stats['errors'].append(str(step_error))
                            import traceback
                            traceback.print_exc()
                            break
                    
                    # ì—í”¼ì†Œë“œ ì™„ë£Œ
                    episode_time = time.time() - episode_start_time
                    
                    # í´ëŸ¬ìŠ¤í„° ë³‘í•©
                    try:
                        dpmm.merge(threshold=1.5)
                    except Exception as merge_error:
                        print(f"Warning: DPMM merge failed: {merge_error}")
                    
                    # í†µê³„ ì—…ë°ì´íŠ¸
                    task_stats['episodes'] += 1
                    task_stats['total_steps'] += episode_steps
                    task_stats['total_reward'] += episode_reward
                    task_stats['episode_rewards'].append(episode_reward)
                    
                    global_stats['total_episodes'] += 1
                    global_stats['total_steps'] += episode_steps
                    global_stats['total_rewards'].append(episode_reward)
                    
                    # ì—í”¼ì†Œë“œ ìš”ì•½
                    avg_loss = np.mean([l['total_loss'] for l in episode_losses]) if episode_losses else 0.0
                    print(f"  âœ“ Episode {episode + 1} completed:")
                    print(f"    Steps: {episode_steps}, Time: {episode_time:.1f}s")
                    print(f"    Reward: {episode_reward:.3f}, Avg Loss: {avg_loss:.6f}")
                    print(f"    Experts used: {len(task_stats['expert_usage'])}")
                
                # íƒœìŠ¤í¬ ì™„ë£Œ
                task_time = time.time() - task_start_time
                avg_reward = task_stats['total_reward'] / task_stats['episodes'] if task_stats['episodes'] > 0 else 0.0
                
                # í´ëŸ¬ìŠ¤í„° ì •ë³´
                try:
                    cluster_info = dpmm.get_cluster_info()
                except Exception as cluster_error:
                    print(f"Warning: Failed to get cluster info: {cluster_error}")
                    cluster_info = {'num_clusters': len(experts)}
                
                print(f"\nğŸ¯ Task '{task['name']}' completed!")
                print(f"  Time: {task_time:.1f}s")
                print(f"  Episodes: {task_stats['episodes']}")
                print(f"  Total steps: {task_stats['total_steps']}")
                print(f"  Average reward: {avg_reward:.3f}")
                print(f"  Total clusters: {cluster_info['num_clusters']}")
                print(f"  Expert usage: {task_stats['expert_usage']}")
                if task_stats['errors']:
                    print(f"  Errors: {len(task_stats['errors'])}")
                
                # íƒœìŠ¤í¬ ê²°ê³¼ ì €ì¥
                global_stats['task_results'][task['name']] = task_stats
                
            except Exception as task_error:
                print(f"âŒ Task '{task['name']}' failed: {task_error}")
                global_stats['task_results'][task['name']] = {'error': str(task_error)}
                import traceback
                traceback.print_exc()
                
            finally:
                # í™˜ê²½ ì •ë¦¬
                if env is not None:
                    try:
                        print("ğŸ”„ Closing environment safely...")
                        env.close()
                        print("âœ“ Environment closed")
                    except Exception as close_error:
                        print(f"Warning: Environment close failed: {close_error}")
                
                # ë©”ëª¨ë¦¬ ì •ë¦¬
                safe_cleanup()
                
                # íƒœìŠ¤í¬ ê°„ ëŒ€ê¸° ì‹œê°„
                if task_idx < len(tasks) - 1:
                    print("â³ Waiting for system stabilization...")
                    time.sleep(2.0)
        
        # ì „ì²´ í•™ìŠµ ì™„ë£Œ
        print(f"\n{'='*60}")
        print("ğŸ‰ Training Completed!")
        print(f"{'='*60}")
        print(f"ğŸ“Š Global Statistics:")
        print(f"  Total episodes: {global_stats['total_episodes']}")
        print(f"  Total steps: {global_stats['total_steps']}")
        print(f"  Total experts: {len(experts)}")
        
        try:
            cluster_info = dpmm.get_cluster_info()
            print(f"  Final clusters: {cluster_info['num_clusters']}")
        except:
            print(f"  Final clusters: {len(experts)}")
        
        if global_stats['total_rewards']:
            avg_reward = np.mean(global_stats['total_rewards'])
            print(f"  Average reward: {avg_reward:.3f}")
        
        # ê²°ê³¼ ì €ì¥
        try:
            results_file = os.path.join(args.save_dir, "training_results.yaml")
            with open(results_file, 'w') as f:
                # numpy ë°°ì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                save_stats = global_stats.copy()
                save_stats['total_rewards'] = [float(r) for r in save_stats['total_rewards']]
                yaml.dump(save_stats, f, default_flow_style=False)
            print(f"âœ“ Results saved to {results_file}")
            
            # ëª¨ë¸ ì €ì¥
            models_dir = os.path.join(args.save_dir, "models")
            os.makedirs(models_dir, exist_ok=True)
            
            for i, expert in enumerate(experts):
                try:
                    model_path = os.path.join(models_dir, f"expert_{i}.pth")
                    expert.save(model_path)
                except Exception as save_error:
                    print(f"Warning: Failed to save expert {i}: {save_error}")
            
            # DPMM ìƒíƒœ ì €ì¥
            try:
                dpmm_path = os.path.join(args.save_dir, "dpmm_state.pkl")
                dpmm.save_state(dpmm_path)
                print(f"âœ“ DPMM state saved to {dpmm_path}")
            except Exception as dpmm_save_error:
                print(f"Warning: Failed to save DPMM state: {dpmm_save_error}")
            
            print(f"âœ“ Models saved to {models_dir}")
            
        except Exception as save_error:
            print(f"âš ï¸ Failed to save results: {save_error}")

    except Exception as main_error:
        print(f"âŒ Main training error: {main_error}")
        import traceback
        traceback.print_exc()
    
    finally:
        # ì‹œë®¬ë ˆì´ì…˜ ì •ë¦¬
        print("\nğŸ”„ Final cleanup...")
        try:
            # ìµœì¢… ë©”ëª¨ë¦¬ ì •ë¦¬
            safe_cleanup()
            
            # ì‹œë®¬ë ˆì´ì…˜ ì¢…ë£Œ
            sim.close()
            print("âœ“ Simulation closed")
        except Exception as close_error:
            print(f"Warning: Final cleanup failed: {close_error}")
        
        print("âœ… All cleanup completed!")

if __name__ == "__main__":
    main()