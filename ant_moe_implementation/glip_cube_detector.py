import torch
import numpy as np
from transformers import AutoProcessor, AutoModelForZeroShotObjectDetection
from PIL import Image
import cv2

class GLIPCubeDetector:
    """GLIP ê¸°ë°˜ íŒŒë€ íë¸Œ ê°ì§€ê¸°"""
    
    def __init__(self, model_name="IDEA-Research/grounding-dino-tiny", confidence_threshold=0.3):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.confidence_threshold = confidence_threshold
        
        try:
            print(f"ğŸ” Loading GLIP model: {model_name}")
            self.processor = AutoProcessor.from_pretrained(model_name)
            self.model = AutoModelForZeroShotObjectDetection.from_pretrained(model_name)
            self.model.to(self.device)
            self.model.eval()
            print("âœ… GLIP model loaded successfully")
            self.model_loaded = True
            
        except Exception as e:
            print(f"âš ï¸ GLIP model loading failed: {e}")
            print("ğŸ”„ Falling back to simple color detection")
            self.model_loaded = False
    
    def detect_cube(self, rgb_image, text_prompt="blue cube"):
        """
        GLIPìœ¼ë¡œ íë¸Œ ê°ì§€
        
        Args:
            rgb_image: numpy array (H, W, 3)
            text_prompt: ê°ì§€í•  ê°ì²´ ì„¤ëª…
            
        Returns:
            boxes: List of [x1, y1, x2, y2] bounding boxes
            scores: List of confidence scores
        """
        if not self.model_loaded:
            return self._fallback_color_detection(rgb_image)
        
        try:
            # numpyë¥¼ PIL Imageë¡œ ë³€í™˜
            pil_image = Image.fromarray(rgb_image)
            
            # GLIP ì…ë ¥ ì¤€ë¹„
            inputs = self.processor(
                images=pil_image, 
                text=text_prompt, 
                return_tensors="pt"
            ).to(self.device)
            
            # ì¶”ë¡ 
            with torch.no_grad():
                outputs = self.model(**inputs)
            
            # ê²°ê³¼ í›„ì²˜ë¦¬
            results = self.processor.post_process_grounded_object_detection(
                outputs,
                inputs.input_ids,
                box_threshold=self.confidence_threshold,
                text_threshold=self.confidence_threshold,
                target_sizes=[pil_image.size[::-1]]  # (height, width)
            )[0]
            
            boxes = results["boxes"].cpu().numpy()
            scores = results["scores"].cpu().numpy()
            
            return boxes, scores
            
        except Exception as e:
            print(f"GLIP detection error: {e}")
            return self._fallback_color_detection(rgb_image)
    
    def _fallback_color_detection(self, rgb_image):
        """ìƒ‰ìƒ ê¸°ë°˜ ê°ì§€ (GLIP ì‹¤íŒ¨ ì‹œ ëŒ€ì•ˆ)"""
        try:
            # RGBë¥¼ BGRë¡œ ë³€í™˜
            bgr = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2BGR)
            hsv = cv2.cvtColor(bgr, cv2.COLOR_BGR2HSV)
            
            # íŒŒë€ìƒ‰ ë²”ìœ„
            lower_blue = np.array([100, 50, 50])
            upper_blue = np.array([130, 255, 255])
            
            # ë§ˆìŠ¤í¬ ìƒì„±
            mask = cv2.inRange(hsv, lower_blue, upper_blue)
            
            # ì»¨íˆ¬ì–´ ì°¾ê¸°
            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            boxes = []
            scores = []
            
            for contour in contours:
                area = cv2.contourArea(contour)
                if area > 100:  # ìµœì†Œ í¬ê¸° í•„í„°
                    x, y, w, h = cv2.boundingRect(contour)
                    boxes.append([x, y, x + w, y + h])
                    scores.append(0.8)  # ê³ ì • ì‹ ë¢°ë„
            
            return np.array(boxes), np.array(scores)
            
        except Exception as e:
            print(f"Fallback detection error: {e}")
            return np.array([]), np.array([])
    
    def get_best_detection(self, rgb_image, depth_image, camera_intrinsics):
        """
        ìµœê³  ì‹ ë¢°ë„ì˜ ê°ì§€ ê²°ê³¼ë¥¼ 3D ì¢Œí‘œë¡œ ë³€í™˜
        
        Args:
            rgb_image: RGB ì´ë¯¸ì§€
            depth_image: ê¹Šì´ ì´ë¯¸ì§€
            camera_intrinsics: (fx, fy, cx, cy)
            
        Returns:
            world_pos: 3D ì›”ë“œ ì¢Œí‘œ [x, y, z] ë˜ëŠ” None
        """
        boxes, scores = self.detect_cube(rgb_image)
        
        if len(boxes) == 0:
            return None
        
        # ê°€ì¥ ë†’ì€ ì‹ ë¢°ë„ì˜ ë°•ìŠ¤ ì„ íƒ
        best_idx = np.argmax(scores)
        best_box = boxes[best_idx]
        
        # ë°•ìŠ¤ ì¤‘ì‹¬ì  ê³„ì‚°
        x1, y1, x2, y2 = best_box
        center_u = int((x1 + x2) / 2)
        center_v = int((y1 + y2) / 2)
        
        # ê¹Šì´ ê°’ ê°€ì ¸ì˜¤ê¸°
        if (0 <= center_v < depth_image.shape[0] and 
            0 <= center_u < depth_image.shape[1]):
            depth = depth_image[center_v, center_u]
        else:
            depth = 2.0  # ê¸°ë³¸ê°’
        
        # 3D ì¢Œí‘œ ê³„ì‚°
        fx, fy, cx, cy = camera_intrinsics
        X = (center_u - cx) * depth / fx
        Y = (center_v - cy) * depth / fy
        Z = depth
        
        return np.array([X, Y, Z], dtype=np.float32)