import numpy as np
import pickle
from sklearn.mixture import BayesianGaussianMixture
from collections import defaultdict, Counter

class RobustDPMMOODDetector:
    """ì•ˆì „í•œ DPMM OOD ê²€ì¶œê¸°"""
    
    def __init__(self, latent_dim=32, alpha=1.0, max_components=10):
        self.latent_dim = latent_dim
        self.alpha = alpha
        self.max_components = max_components
        
        # í´ëŸ¬ìŠ¤í„° ë°ì´í„° ì €ì¥
        self.cluster_data = defaultdict(list)
        self.cluster_centers = {}
        self.cluster_counts = Counter()
        self.next_cluster_id = 0
        
        # ë² ì´ì§€ì•ˆ GMM ëª¨ë¸
        self.bgmm = BayesianGaussianMixture(
            n_components=max_components,
            covariance_type='full',
            weight_concentration_prior=alpha,
            random_state=42
        )
        self.is_fitted = False
        
        print(f"âœ“ RobustDPMMOODDetector initialized: latent_dim={latent_dim}")
    
    def _safe_array_conversion(self, data):
        """ë°ì´í„°ë¥¼ ì•ˆì „í•˜ê²Œ numpy ë°°ì—´ë¡œ ë³€í™˜"""
        try:
            if isinstance(data, np.ndarray):
                return data.astype(np.float32)
            elif hasattr(data, 'numpy'):  # torch tensor
                return data.detach().cpu().numpy().astype(np.float32)
            else:
                return np.array(data, dtype=np.float32)
        except Exception as e:
            print(f"Warning: Array conversion failed: {e}")
            return np.zeros(self.latent_dim, dtype=np.float32)
    
    def assign(self, latent_vector, threshold=2.0):
        """ì ì¬ ë²¡í„°ë¥¼ í´ëŸ¬ìŠ¤í„°ì— í• ë‹¹"""
        try:
            # ì•ˆì „í•œ ë°°ì—´ ë³€í™˜
            z = self._safe_array_conversion(latent_vector)
            if z.ndim > 1:
                z = z.flatten()
            
            # ì°¨ì› í™•ì¸ ë° ì¡°ì •
            if len(z) != self.latent_dim:
                if len(z) > self.latent_dim:
                    z = z[:self.latent_dim]
                else:
                    # íŒ¨ë”©
                    padded = np.zeros(self.latent_dim, dtype=np.float32)
                    padded[:len(z)] = z
                    z = padded
            
            # ì²« ë²ˆì§¸ ë°ì´í„°í¬ì¸íŠ¸ì¸ ê²½ìš°
            if self.next_cluster_id == 0:
                cluster_id = 0
                self.cluster_data[cluster_id].append(z)
                self.cluster_centers[cluster_id] = z.copy()
                self.cluster_counts[cluster_id] += 1
                self.next_cluster_id = 1
                return cluster_id
            
            # ê¸°ì¡´ í´ëŸ¬ìŠ¤í„°ì™€ì˜ ê±°ë¦¬ ê³„ì‚°
            min_distance = float('inf')
            best_cluster = -1
            
            for cluster_id, center in self.cluster_centers.items():
                try:
                    distance = np.linalg.norm(z - center)
                    if distance < min_distance:
                        min_distance = distance
                        best_cluster = cluster_id
                except Exception as dist_error:
                    print(f"Warning: Distance calculation failed: {dist_error}")
                    continue
            
            # ì„ê³„ê°’ ê¸°ë°˜ í• ë‹¹
            if min_distance < threshold and best_cluster >= 0:
                # ê¸°ì¡´ í´ëŸ¬ìŠ¤í„°ì— í• ë‹¹
                cluster_id = best_cluster
                self.cluster_data[cluster_id].append(z)
                self.cluster_counts[cluster_id] += 1
                
                # í´ëŸ¬ìŠ¤í„° ì¤‘ì‹¬ ì—…ë°ì´íŠ¸ (ì´ë™ í‰ê· )
                alpha = 0.1
                self.cluster_centers[cluster_id] = (
                    (1 - alpha) * self.cluster_centers[cluster_id] + alpha * z
                )
            else:
                # ìƒˆë¡œìš´ í´ëŸ¬ìŠ¤í„° ìƒì„±
                cluster_id = self.next_cluster_id
                self.cluster_data[cluster_id].append(z)
                self.cluster_centers[cluster_id] = z.copy()
                self.cluster_counts[cluster_id] = 1
                self.next_cluster_id += 1
            
            return cluster_id
            
        except Exception as e:
            print(f"Warning: Cluster assignment failed: {e}")
            # ì•ˆì „í•œ ê¸°ë³¸ê°’ ë°˜í™˜
            return 0
    
    def merge(self, threshold=1.5):
        """ìœ ì‚¬í•œ í´ëŸ¬ìŠ¤í„°ë“¤ì„ ë³‘í•©"""
        try:
            if len(self.cluster_centers) < 2:
                return
            
            # ë³‘í•©í•  í´ëŸ¬ìŠ¤í„° ìŒ ì°¾ê¸°
            clusters_to_merge = []
            cluster_ids = list(self.cluster_centers.keys())
            
            for i in range(len(cluster_ids)):
                for j in range(i + 1, len(cluster_ids)):
                    id1, id2 = cluster_ids[i], cluster_ids[j]
                    try:
                        distance = np.linalg.norm(
                            self.cluster_centers[id1] - self.cluster_centers[id2]
                        )
                        if distance < threshold:
                            clusters_to_merge.append((id1, id2, distance))
                    except Exception as merge_error:
                        print(f"Warning: Merge distance calculation failed: {merge_error}")
                        continue
            
            # ê±°ë¦¬ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ê°€ì¥ ê°€ê¹Œìš´ ê²ƒë¶€í„° ë³‘í•©
            clusters_to_merge.sort(key=lambda x: x[2])
            
            merged_count = 0
            for id1, id2, distance in clusters_to_merge:
                if id1 in self.cluster_centers and id2 in self.cluster_centers:
                    # id2ë¥¼ id1ìœ¼ë¡œ ë³‘í•©
                    self.cluster_data[id1].extend(self.cluster_data[id2])
                    self.cluster_counts[id1] += self.cluster_counts[id2]
                    
                    # ìƒˆë¡œìš´ ì¤‘ì‹¬ ê³„ì‚°
                    all_data = np.array(self.cluster_data[id1])
                    self.cluster_centers[id1] = np.mean(all_data, axis=0)
                    
                    # id2 ì œê±°
                    del self.cluster_data[id2]
                    del self.cluster_centers[id2]
                    del self.cluster_counts[id2]
                    
                    merged_count += 1
            
            if merged_count > 0:
                print(f"  ğŸ”„ Merged {merged_count} cluster pairs")
                
        except Exception as e:
            print(f"Warning: Cluster merge failed: {e}")
    
    def get_cluster_info(self):
        """í´ëŸ¬ìŠ¤í„° ì •ë³´ ë°˜í™˜"""
        try:
            return {
                'num_clusters': len(self.cluster_centers),
                'cluster_counts': dict(self.cluster_counts),
                'total_points': sum(self.cluster_counts.values())
            }
        except Exception as e:
            print(f"Warning: Failed to get cluster info: {e}")
            return {
                'num_clusters': 0,
                'cluster_counts': {},
                'total_points': 0
            }
    
    def save_state(self, filepath):
        """DPMM ìƒíƒœ ì €ì¥"""
        try:
            state = {
                'cluster_data': dict(self.cluster_data),
                'cluster_centers': self.cluster_centers,
                'cluster_counts': dict(self.cluster_counts),
                'next_cluster_id': self.next_cluster_id,
                'latent_dim': self.latent_dim,
                'alpha': self.alpha,
                'max_components': self.max_components
            }
            
            with open(filepath, 'wb') as f:
                pickle.dump(state, f)
            print(f"âœ“ DPMM state saved to {filepath}")
            
        except Exception as e:
            print(f"Warning: Failed to save DPMM state: {e}")
    
    def load_state(self, filepath):
        """DPMM ìƒíƒœ ë¡œë“œ"""
        try:
            with open(filepath, 'rb') as f:
                state = pickle.load(f)
            
            self.cluster_data = defaultdict(list, state['cluster_data'])
            self.cluster_centers = state['cluster_centers']
            self.cluster_counts = Counter(state['cluster_counts'])
            self.next_cluster_id = state['next_cluster_id']
            self.latent_dim = state['latent_dim']
            self.alpha = state['alpha']
            self.max_components = state['max_components']
            
            print(f"âœ“ DPMM state loaded from {filepath}")
            
        except Exception as e:
            print(f"Warning: Failed to load DPMM state: {e}")