#!/usr/bin/env python3
"""
ë§¤ìš° ì•ˆì „í•œ SB3 í•™ìŠµ - ëª¨ë“  íƒ€ì… ë³€í™˜ ë¬¸ì œ í•´ê²°
"""

import argparse
import os
import numpy as np
import torch
from isaaclab.app import AppLauncher

def main():
    parser = argparse.ArgumentParser(description="Ultra Safe SB3 Training")
    parser.add_argument("--timesteps", type=int, default=3000)
    parser.add_argument("--save_path", type=str, default="./ultra_safe_sac_model")
    AppLauncher.add_app_launcher_args(parser)
    args = parser.parse_args()

    app = AppLauncher(vars(args))
    sim = app.app

    try:
        from stable_baselines3 import SAC
        from stable_baselines3.common.monitor import Monitor
        from fixed_simple_gym_wrapper import SimpleAntPushWrapper

        print(f"ğŸš€ Ultra Safe SB3 Training")
        print(f"  PyTorch version: {torch.__version__}")
        print(f"  CUDA available: {torch.cuda.is_available()}")
        print(f"  Timesteps: {args.timesteps}")
        
        # í™˜ê²½ ìƒì„±
        print(f"ğŸ—ï¸ Creating environment...")
        base_env = SimpleAntPushWrapper(custom_cfg={
            'cube_position': [2.0, 0.0, 0.1],
            'goal_position': [3.0, 0.0, 0.1]
        })
        
        # Monitorë¡œ ë˜í•‘ (SB3 í˜¸í™˜ì„± í–¥ìƒ)
        env = Monitor(base_env)
        
        print(f"ğŸ“Š Environment info:")
        print(f"  Observation space: {env.observation_space}")
        print(f"  Action space: {env.action_space}")
        
        # í™˜ê²½ ì•ˆì „ì„± í…ŒìŠ¤íŠ¸
        print(f"ğŸ§ª Testing environment safety...")
        test_passed = True
        
        try:
            # ë¦¬ì…‹ í…ŒìŠ¤íŠ¸
            obs, info = env.reset()
            print(f"  âœ… Reset: obs shape {obs.shape}, type {type(obs)}")
            
            # ìŠ¤í… í…ŒìŠ¤íŠ¸
            for i in range(5):
                action = env.action_space.sample()
                obs, reward, done, truncated, info = env.step(action)
                
                # íƒ€ì… ê²€ì¦
                assert isinstance(obs, np.ndarray), f"obs should be numpy array, got {type(obs)}"
                assert isinstance(reward, (int, float, np.number)), f"reward should be number, got {type(reward)}"
                assert isinstance(done, (bool, np.bool_)), f"done should be bool, got {type(done)}"
                assert isinstance(truncated, (bool, np.bool_)), f"truncated should be bool, got {type(truncated)}"
                
                print(f"  âœ… Step {i+1}: obs {obs.shape}, reward {reward:.3f}, done {done}")
                
                if done or truncated:
                    obs, info = env.reset()
                    print(f"  âœ… Reset after done: obs {obs.shape}")
            
        except Exception as e:
            print(f"  âŒ Environment test failed: {e}")
            test_passed = False
        
        if not test_passed:
            print("âŒ Environment test failed, aborting training")
            return
        
        print(f"âœ… Environment test passed!")
        
        # SAC ì—ì´ì „íŠ¸ ìƒì„± (ë³´ìˆ˜ì  ì„¤ì •)
        print(f"ğŸ¤– Creating SAC agent...")
        model = SAC(
            "MlpPolicy",
            env,
            learning_rate=1e-4,     # ë‚®ì€ í•™ìŠµë¥ 
            buffer_size=2000,       # ì‘ì€ ë²„í¼
            learning_starts=50,     # ë¹ ë¥¸ ì‹œì‘
            batch_size=16,          # ì‘ì€ ë°°ì¹˜
            tau=0.01,               # ë¹ ë¥¸ íƒ€ê²Ÿ ì—…ë°ì´íŠ¸
            gamma=0.95,             # ë‚®ì€ í• ì¸ìœ¨
            train_freq=1,
            gradient_steps=1,
            policy_kwargs=dict(
                net_arch=[32, 32]   # ë§¤ìš° ì‘ì€ ë„¤íŠ¸ì›Œí¬
            ),
            verbose=1,
            device="cuda" if torch.cuda.is_available() else "cpu"
        )
        
        print(f"ğŸ“Š Model info:")
        print(f"  Device: {model.device}")
        print(f"  Buffer size: {model.buffer_size}")
        print(f"  Network architecture: {model.policy.net_arch}")
        
        # í•™ìŠµ ì‹œì‘
        print(f"ğŸ“ Starting training...")
        try:
            model.learn(
                total_timesteps=args.timesteps,
                log_interval=2,
                progress_bar=True,
                callback=None
            )
            
            print(f"âœ… Training completed successfully!")
            
        except Exception as e:
            print(f"âš ï¸ Training interrupted: {e}")
            print("Attempting to save partial model...")
        
        # ëª¨ë¸ ì €ì¥
        try:
            model.save(args.save_path)
            print(f"ğŸ’¾ Model saved to: {args.save_path}")
        except Exception as e:
            print(f"âš ï¸ Model save failed: {e}")
        
        # í•™ìŠµëœ ëª¨ë¸ í…ŒìŠ¤íŠ¸
        print(f"ğŸ§ª Testing trained model...")
        try:
            obs, _ = env.reset()
            total_reward = 0
            episode_length = 0
            
            for step in range(100):
                action, _ = model.predict(obs, deterministic=True)
                obs, reward, done, truncated, info = env.step(action)
                total_reward += reward
                episode_length += 1
                
                if step % 20 == 0:
                    print(f"  Step {step}: reward={reward:.3f}, total={total_reward:.3f}")
                
                if done or truncated:
                    print(f"  Episode finished at step {step}")
                    break
            
            print(f"âœ… Test completed!")
            print(f"  Episode length: {episode_length}")
            print(f"  Total reward: {total_reward:.2f}")
            print(f"  Average reward: {total_reward/episode_length:.3f}")
            
        except Exception as e:
            print(f"âš ï¸ Testing failed: {e}")
        
    except Exception as e:
        print(f"âŒ Training failed: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        try:
            env.close()
            print("ğŸ”’ Environment closed")
        except:
            pass
        sim.close()
        print("ğŸ”’ Simulator closed")

if __name__ == "__main__":
    main()