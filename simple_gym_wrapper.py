import gymnasium as gym
import numpy as np
from gymnasium.spaces import Box
from isaaclab.envs import ManagerBasedRLEnv
from isaaclab_tasks.manager_based.classic.ant.ant_env_cfg import AntEnvCfg, MySceneCfg
from config import CONFIG

class SimpleAntPushWrapper(gym.Wrapper):
    """ê°€ì¥ ê°„ë‹¨í•œ Gym Wrapper"""
    def __init__(self, custom_cfg=None):
        # IsaacLab í™˜ê²½ ìƒì„±
        cfg = AntEnvCfg()
        cfg.scene = MySceneCfg(num_envs=1, env_spacing=cfg.scene.env_spacing)
        cfg.sim.device = str(CONFIG.device)
        cfg.seed = 42
        
        self.isaac_env = ManagerBasedRLEnv(cfg=cfg)
        
        # Gym í™˜ê²½ìœ¼ë¡œ ë˜í•‘
        super().__init__(self.isaac_env)
        
        # ì»¤ìŠ¤í…€ ì„¤ì •
        c = custom_cfg or {}
        self.cube_pos = np.array(c.get('cube_position', [2.0, 0.0, 0.1]), dtype=np.float32)
        self.goal_pos = np.array(c.get('goal_position', [3.0, 0.0, 0.1]), dtype=np.float32)
        
        # ê´€ì¸¡ ê³µê°„ ì¬ì •ì˜ (policy obs + cube_pos + goal_pos)
        base_obs_space = self.isaac_env.observation_space['policy']
        base_dim = base_obs_space.shape[0]
        
        self.observation_space = Box(
            low=-np.inf, high=np.inf, 
            shape=(base_dim + 6,),  # +3 for cube, +3 for goal
            dtype=np.float32
        )
        
        # ì•¡ì…˜ ê³µê°„ì€ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        self.action_space = self.isaac_env.action_space
        
        print(f"ğŸ—ï¸ Simple Ant Push Wrapper created")
        print(f"  Obs space: {self.observation_space.shape}")
        print(f"  Action space: {self.action_space.shape}")
    
    def reset(self, **kwargs):
        """ë¦¬ì…‹"""
        obs_dict, info = self.isaac_env.reset()
        obs = self._process_obs(obs_dict)
        return obs, info
    
    def step(self, action):
        """ìŠ¤í…"""
        # actionì„ ì˜¬ë°”ë¥¸ í˜•íƒœë¡œ ë³€í™˜
        if isinstance(action, np.ndarray) and action.ndim == 1:
            action = action.reshape(1, -1)
        
        obs_dict, reward, terminated, truncated, info = self.isaac_env.step(action)
        obs = self._process_obs(obs_dict)
        
        # ì»¤ìŠ¤í…€ ë³´ìƒ ê³„ì‚°
        custom_reward = self._compute_reward(obs)
        
        # í…ì„œë¥¼ ìŠ¤ì¹¼ë¼ë¡œ ë³€í™˜
        if hasattr(terminated, 'item'):
            terminated = terminated.item()
        if hasattr(truncated, 'item'):
            truncated = truncated.item()
        
        return obs, float(custom_reward), bool(terminated), bool(truncated), info
    
    def _process_obs(self, obs_dict):
        """ê´€ì¸¡ê°’ ì²˜ë¦¬"""
        base_obs = obs_dict['policy']
        
        # í…ì„œë¥¼ numpyë¡œ ë³€í™˜
        if hasattr(base_obs, 'cpu'):
            base_obs = base_obs.cpu().numpy()
        
        # ë‹¤ì¤‘ í™˜ê²½ ì²˜ë¦¬
        if base_obs.ndim == 2:
            base_obs = base_obs[0]  # ì²« ë²ˆì§¸ í™˜ê²½ë§Œ ì‚¬ìš©
        
        # ë”ë¯¸ cube/goal ìœ„ì¹˜ (ì‹¤ì œë¡œëŠ” í™˜ê²½ì—ì„œ ê°€ì ¸ì™€ì•¼ í•¨)
        cube_pos = self.cube_pos
        goal_pos = self.goal_pos
        
        # ì—°ê²°
        full_obs = np.concatenate([base_obs.flatten(), cube_pos, goal_pos])
        return full_obs.astype(np.float32)
    
    def _compute_reward(self, obs):
        """ê°„ë‹¨í•œ ë³´ìƒ í•¨ìˆ˜"""
        # ë§ˆì§€ë§‰ 6ê°œ ì°¨ì›ì´ cube_pos(3) + goal_pos(3)
        cube_pos = obs[-6:-3]
        goal_pos = obs[-3:]
        
        # ê±°ë¦¬ ê¸°ë°˜ ë³´ìƒ
        distance = np.linalg.norm(cube_pos - goal_pos)
        reward = -distance  # ê±°ë¦¬ê°€ ê°€ê¹Œìš¸ìˆ˜ë¡ ë†’ì€ ë³´ìƒ
        
        return reward
    
    def close(self):
        """í™˜ê²½ ì¢…ë£Œ"""
        self.isaac_env.close()