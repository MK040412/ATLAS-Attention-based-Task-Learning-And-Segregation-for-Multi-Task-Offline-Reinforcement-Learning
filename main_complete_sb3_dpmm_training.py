#!/usr/bin/env python3
"""
ì™„ì „í•œ SB3-DPMM í†µí•© í•™ìŠµ (Birth ë¬¸ì œ í•´ê²° + ë³‘ë ¬ í™˜ê²½ + ì‹¤ì‹œê°„ ì‹œê°í™”)
"""

import argparse
import torch
import numpy as np
import yaml
import os
from isaaclab.app import AppLauncher

def main():
    parser = argparse.ArgumentParser(description="Complete SB3-DPMM MoE SAC Training (Fixed)")
    parser.add_argument("--tasks", type=str, default="tasks.yaml")
    parser.add_argument("--save_dir", type=str, default="./fixed_sb3_outputs")
    parser.add_argument("--num_envs", type=int, default=256)  # ë³‘ë ¬ í™˜ê²½ ì§€ì›
    parser.add_argument("--episodes", type=int, default=100)
    parser.add_argument("--max_steps", type=int, default=500)
    
    # ğŸ”§ ê°œì„ ëœ DPMM íŒŒë¼ë¯¸í„°
    parser.add_argument("--tau_birth", type=float, default=-2.0)
    parser.add_argument("--tau_merge_kl", type=float, default=0.3)
    parser.add_argument("--initial_variance", type=float, default=0.1)
    parser.add_argument("--max_clusters", type=int, default=15)
    parser.add_argument("--target_birth_rate", type=float, default=0.12)
    
    parser.add_argument("--latent_dim", type=int, default=24)
    parser.add_argument("--update_freq", type=int, default=8)
    parser.add_argument("--merge_freq", type=int, default=15)
    parser.add_argument("--checkpoint_freq", type=int, default=20)
    parser.add_argument("--monitor_freq", type=int, default=5)
    parser.add_argument("--plot_freq", type=int, default=25)  # ì‹¤ì‹œê°„ í”Œë¡¯ ì£¼ê¸°
    
    AppLauncher.add_app_launcher_args(parser)
    args = parser.parse_args()

    app = AppLauncher(vars(args))
    sim = app.app

    try:
        # í•„ìš”í•œ ëª¨ë“ˆë“¤ import
        from ant_push_env import IsaacAntPushEnv  # ë³‘ë ¬ í™˜ê²½ ì§€ì›
        from improved_sb3_dpmm_agent import ImprovedSB3DPMMAgent
        from language_processor import LanguageProcessor
        from experiment_visualization import ExperimentVisualizer, analyze_birth_problem
        from config import CONFIG

        print(f"ğŸš€ Fixed SB3-DPMM Training Started")
        print(f"  ğŸ”§ Birth Control Parameters:")
        print(f"    â€¢ tau_birth: {args.tau_birth} (was -5.0)")
        print(f"    â€¢ tau_merge_kl: {args.tau_merge_kl} (was 0.1)")
        print(f"    â€¢ initial_variance: {args.initial_variance}")
        print(f"    â€¢ max_clusters: {args.max_clusters}")
        print(f"    â€¢ target_birth_rate: {args.target_birth_rate * 100:.1f}%")
        print(f"  ğŸ“Š Training Parameters:")
        print(f"    â€¢ Parallel environments: {args.num_envs}")
        print(f"    â€¢ Episodes per task: {args.episodes}")
        print(f"    â€¢ Latent dimension: {args.latent_dim}")

        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(args.save_dir, exist_ok=True)
        
        # ì‹¤ì‹œê°„ ì‹œê°í™” ì´ˆê¸°í™”
        visualizer = ExperimentVisualizer(save_dir=args.save_dir)

        # íƒœìŠ¤í¬ ë¡œë“œ
        tasks = load_or_create_tasks(args.tasks, args.episodes)
        
        # ì–¸ì–´ ì²˜ë¦¬ê¸°
        lang_processor = LanguageProcessor(device=CONFIG.device)
        
        # í†µí•© ì—ì´ì „íŠ¸ (ì²« ë²ˆì§¸ íƒœìŠ¤í¬ì—ì„œ ì´ˆê¸°í™”)
        agent = None
        
        # ì „ì²´ í•™ìŠµ í†µê³„ (Birth ëª¨ë‹ˆí„°ë§ ì¶”ê°€)
        all_training_stats = {
            'tasks': [],
            'episode_rewards': [],
            'cluster_evolution': [],
            'expert_evolution': [],
            'dpmm_events': [],
            'birth_rate_history': [],
            'tau_birth_history': [],
            'merge_history': []
        }

        # íƒœìŠ¤í¬ë³„ í•™ìŠµ
        for task_idx, task in enumerate(tasks):
            print(f"\n{'='*70}")
            print(f"ğŸ¯ Task {task_idx + 1}/{len(tasks)}: {task['name']}")
            print(f"ğŸ“ Instruction: {task['instruction']}")
            print(f"{'='*70}")
            
            # ë³‘ë ¬ í™˜ê²½ ìƒì„± (main_kl_dpmm_training.py ë°©ì‹)
            env = IsaacAntPushEnv(custom_cfg=task['env_cfg'], num_envs=args.num_envs)
            
            # ì´ˆê¸° ìƒíƒœë¡œ ì°¨ì› í™•ì¸
            state, _ = env.reset()
            state_dim = state.shape[0] if len(state.shape) == 1 else state.shape[1]
            action_dim = env.action_space.shape[1] if len(env.action_space.shape) == 2 else env.action_space.shape[0]
            
            print(f"ğŸ”§ Environment Setup:")
            print(f"  â€¢ State dim: {state_dim}")
            print(f"  â€¢ Action dim: {action_dim}")
            print(f"  â€¢ Parallel envs: {args.num_envs}")
            print(f"  â€¢ Action space: {env.action_space.shape}")
            
            # ì§€ì‹œì‚¬í•­ ì„ë² ë”©
            instr_emb = lang_processor.encode(task['instruction'])
            instr_dim = instr_emb.shape[-1]
            
            print(f"  â€¢ Instruction embedding dim: {instr_dim}")
            
            # ì—ì´ì „íŠ¸ ì´ˆê¸°í™” (ì²« ë²ˆì§¸ íƒœìŠ¤í¬ì—ì„œë§Œ)
            if agent is None:
                agent = ImprovedSB3DPMMAgent(
                    state_dim=state_dim,
                    action_dim=action_dim,
                    instr_dim=instr_dim,
                    latent_dim=args.latent_dim,
                    tau_birth=args.tau_birth,
                    tau_merge_kl=args.tau_merge_kl,
                    initial_variance=args.initial_variance,
                    max_clusters=args.max_clusters,
                    target_birth_rate=args.target_birth_rate,
                    device=str(CONFIG.device)
                )
                print(f"ğŸ¤– Improved SB3-DPMM Agent initialized with birth control")
            
            # íƒœìŠ¤í¬ë³„ í†µê³„
            task_stats = {
                'task_name': task['name'],
                'episode_rewards': [],
                'cluster_counts': [],
                'expert_counts': [],
                'birth_rates': [],
                'dpmm_events': [],
                'early_stop_triggered': False
            }
            
            # Birth rate ê²½ê³  ì¹´ìš´í„°
            high_birth_rate_warnings = 0
            
            # ì—í”¼ì†Œë“œ í•™ìŠµ
            for episode in range(args.episodes):
                print(f"\n--- Episode {episode + 1}/{args.episodes} ---")
                
                # í™˜ê²½ ë¦¬ì…‹
                state, _ = env.reset()
                episode_reward = 0
                step_count = 0
                
                while step_count < args.max_steps:
                    try:
                        # í–‰ë™ ì„ íƒ (ë³‘ë ¬ í™˜ê²½ ì²˜ë¦¬)
                        if len(state.shape) == 2:  # ë³‘ë ¬ í™˜ê²½
                            # ì²« ë²ˆì§¸ í™˜ê²½ë§Œ ì‚¬ìš©í•˜ê±°ë‚˜ í‰ê·  ì‚¬ìš©
                            single_state = state[0] if state.shape[0] > 1 else state.squeeze(0)
                        else:
                            single_state = state
                        
                        action, cluster_id = agent.select_action(
                            single_state, 
                            instr_emb.squeeze(0).detach().cpu().numpy(),
                            deterministic=False
                        )
                        
                        if step_count == 0:
                            print(f"  ğŸ¯ Assigned to cluster/expert: {cluster_id}")
                        
                        # ë³‘ë ¬ í™˜ê²½ì„ ìœ„í•œ ì•¡ì…˜ í™•ì¥
                        if args.num_envs > 1:
                            # ëª¨ë“  í™˜ê²½ì— ê°™ì€ ì•¡ì…˜ ì ìš©
                            action_batch = np.tile(action, (args.num_envs, 1))
                        else:
                            action_batch = action
                        
                        # í™˜ê²½ ìŠ¤í…
                        next_state, reward, done, info = env.step(action_batch)
                        
                        # ë³‘ë ¬ í™˜ê²½ ì²˜ë¦¬
                        if isinstance(reward, np.ndarray):
                            episode_reward += reward.mean()  # í‰ê·  ë³´ìƒ
                            done = done.any()  # í•˜ë‚˜ë¼ë„ ëë‚˜ë©´ ì¢…ë£Œ
                        else:
                            episode_reward += reward
                        
                        # ê²½í—˜ ì €ì¥ (ë‹¨ì¼ ìƒíƒœë¡œ ë³€í™˜)
                        if len(next_state.shape) == 2:
                            next_single_state = next_state[0]
                        else:
                            next_single_state = next_state
                        
                        agent.store_experience(
                            single_state, action, reward if not isinstance(reward, np.ndarray) else reward.mean(), 
                            next_single_state, done, cluster_id
                        )
                        
                        state = next_state
                        step_count += 1
                        
                        if done:
                            break
                            
                    except Exception as e:
                        print(f"  âš ï¸ Episode step error: {e}")
                        break
                
                # ì£¼ê¸°ì  ì—…ë°ì´íŠ¸
                if episode % args.update_freq == 0 and episode > 0:
                    try:
                        update_results = agent.update_experts(batch_size=128)
                        if update_results and episode % (args.update_freq * 2) == 0:
                            updated_experts = len([k for k, v in update_results.items() if v is not None])
                            print(f"  ğŸ“ˆ Updated {updated_experts} experts")
                    except Exception as e:
                        print(f"  âš ï¸ Expert update error: {e}")
                
                # DPMM í´ëŸ¬ìŠ¤í„° ë³‘í•©
                if episode % args.merge_freq == 0 and episode > 0:
                    try:
                        merged_count = agent.merge_clusters_aggressive(verbose=(episode % (args.merge_freq * 2) == 0))
                        if merged_count > 0:
                            task_stats['dpmm_events'].append({
                                'episode': episode,
                                'type': 'merge',
                                'count': merged_count
                            })
                            all_training_stats['merge_history'].append(episode)
                    except Exception as e:
                        print(f"  âš ï¸ Cluster merge error: {e}")
                
                # ğŸ” Birth Rate ëª¨ë‹ˆí„°ë§
                if episode % args.monitor_freq == 0 and episode > 0:
                    try:
                        dpmm_stats = agent.get_dpmm_statistics()
                        current_birth_rate = dpmm_stats.get('recent_birth_rate', 0.0)
                        current_tau_birth = dpmm_stats.get('current_tau_birth', args.tau_birth)
                        
                        task_stats['birth_rates'].append(current_birth_rate)
                        all_training_stats['birth_rate_history'].append(current_birth_rate)
                        all_training_stats['tau_birth_history'].append(current_tau_birth)
                        
                        # ë†’ì€ birth rate ê²½ê³ 
                        if current_birth_rate > 0.25:
                            high_birth_rate_warnings += 1
                            print(f"  âš ï¸ HIGH BIRTH RATE: {current_birth_rate:.1%} (tau_birth: {current_tau_birth:.3f})")
                            
                            if high_birth_rate_warnings >= 3:
                                print(f"  ğŸ›‘ Triggering emergency cluster merge...")
                                emergency_merges = agent.emergency_cluster_reduction()
                                print(f"  ğŸ”§ Emergency merged {emergency_merges} clusters")
                                high_birth_rate_warnings = 0
                        
                        elif episode % (args.monitor_freq * 3) == 0:
                            print(f"  ğŸ“Š Birth rate: {current_birth_rate:.1%}, Clusters: {dpmm_stats.get('num_clusters', 0)}")
                        
                    except Exception as e:
                        print(f"  âš ï¸ Birth rate monitoring error: {e}")
                
                # í†µê³„ ìˆ˜ì§‘
                task_stats['episode_rewards'].append(episode_reward)
                
                try:
                    agent_info = agent.get_info()
                    task_stats['cluster_counts'].append(agent_info['dpmm']['num_clusters'])
                    task_stats['expert_counts'].append(agent_info['num_experts'])
                except:
                    task_stats['cluster_counts'].append(0)
                    task_stats['expert_counts'].append(0)
                
                # í´ëŸ¬ìŠ¤í„° í­ë°œ ì¡°ê¸° ê°ì§€
                current_clusters = task_stats['cluster_counts'][-1] if task_stats['cluster_counts'] else 0
                if current_clusters > args.max_clusters * 1.5:
                    print(f"  ğŸš¨ CLUSTER EXPLOSION DETECTED: {current_clusters} clusters!")
                    print(f"  ğŸ›‘ Triggering emergency stop and reset...")
                    task_stats['early_stop_triggered'] = True
                    break
                
                # ğŸ“Š ì‹¤ì‹œê°„ ì‹œê°í™” (ì£¼ê¸°ì )
                if episode % args.plot_freq == 0 and episode > 0:
                    try:
                        # í˜„ì¬ê¹Œì§€ì˜ í†µê³„ë¡œ ì„ì‹œ ì‹œê°í™”
                        temp_stats = {
                            'episode_rewards': task_stats['episode_rewards'],
                            'cluster_evolution': task_stats['cluster_counts'],
                            'expert_evolution': task_stats['expert_counts'],
                            'dpmm_events': task_stats['dpmm_events']
                        }
                        
                        print(f"  ğŸ“ˆ Generating real-time plots...")
                        visualizer.plot_training_curves(
                            temp_stats, 
                            title=f"Task {task_idx+1}: {task['name']} - Episode {episode}"
                        )
                        
                        if len(task_stats['dpmm_events']) > 0:
                            analyze_birth_problem(temp_stats)
                        
                    except Exception as e:
                        print(f"  âš ï¸ Real-time plotting error: {e}")
                
                # ì£¼ê¸°ì  ìƒì„¸ ì¶œë ¥
                if episode % 20 == 0 and episode > 0:
                    try:
                        agent_info = agent.get_info()
                        dpmm_stats = agent.get_dpmm_statistics()
                        recent_rewards = task_stats['episode_rewards'][-10:]
                        
                        print(f"  ğŸ“Š Episode {episode + 1} Detailed Summary:")
                        print(f"    â€¢ Episode reward: {episode_reward:.2f}")
                        print(f"    â€¢ Recent avg reward: {np.mean(recent_rewards):.2f}")
                        print(f"    â€¢ Steps: {step_count}")
                        print(f"    â€¢ Clusters: {agent_info['dpmm']['num_clusters']}")
                        print(f"    â€¢ Experts: {agent_info['num_experts']}")
                        print(f"    â€¢ Birth rate: {dpmm_stats.get('recent_birth_rate', 0):.1%}")
                        print(f"    â€¢ Total births: {dpmm_stats.get('total_births', 0)}")
                        print(f"    â€¢ Total merges: {dpmm_stats.get('total_merges', 0)}")
                        print(f"    â€¢ Current tau_birth: {dpmm_stats.get('current_tau_birth', 0):.3f}")
                        
                    except Exception as e:
                        print(f"  âš ï¸ Stats display error: {e}")
            
            # íƒœìŠ¤í¬ ì™„ë£Œ í›„ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
            if (task_idx + 1) % args.checkpoint_freq == 0:
                checkpoint_path = os.path.join(args.save_dir, f"fixed_checkpoint_task_{task_idx + 1}")
                try:
                    agent.save(checkpoint_path)
                    print(f"ğŸ’¾ Checkpoint saved: {checkpoint_path}")
                except Exception as e:
                    print(f"âš ï¸ Checkpoint save error: {e}")
            
            # íƒœìŠ¤í¬ í†µê³„ ì €ì¥
            all_training_stats['tasks'].append(task_stats)
            all_training_stats['episode_rewards'].extend(task_stats['episode_rewards'])
            all_training_stats['cluster_evolution'].extend(task_stats['cluster_counts'])
            all_training_stats['expert_evolution'].extend(task_stats['expert_counts'])
            all_training_stats['dpmm_events'].extend(task_stats['dpmm_events'])
            
            # íƒœìŠ¤í¬ ìš”ì•½ (ê°œì„ ëœ ì¶œë ¥)
            print(f"\nğŸ Task '{task['name']}' completed!")
            print(f"  ğŸ“ˆ Performance:")
            print(f"    â€¢ Average reward: {np.mean(task_stats['episode_rewards']):.2f}")
            print(f"    â€¢ Best reward: {max(task_stats['episode_rewards']):.2f}")
            print(f"    â€¢ Final reward (last 10): {np.mean(task_stats['episode_rewards'][-10:]):.2f}")
            print(f"  ğŸ§  Model Status:")
            print(f"    â€¢ Final clusters: {task_stats['cluster_counts'][-1] if task_stats['cluster_counts'] else 0}")
            print(f"    â€¢ Final experts: {task_stats['expert_counts'][-1] if task_stats['expert_counts'] else 0}")
            print(f"    â€¢ DPMM events: {len(task_stats['dpmm_events'])}")
            print(f"    â€¢ Early stop: {'Yes' if task_stats['early_stop_triggered'] else 'No'}")
            
            # íƒœìŠ¤í¬ë³„ ìƒì„¸ ì‹œê°í™”
            try:
                print(f"  ğŸ“Š Generating task summary plots...")
                task_specific_stats = {
                    'episode_rewards': task_stats['episode_rewards'],
                    'cluster_evolution': task_stats['cluster_counts'],
                    'expert_evolution': task_stats['expert_counts'],
                    'dpmm_events': task_stats['dpmm_events']
                }
                
                visualizer.plot_training_curves(
                    task_specific_stats,
                    title=f"Task {task_idx+1} Complete: {task['name']}"
                )
                
                # DPMM ìƒì„¸ ë¶„ì„
                if len(task_stats['dpmm_events']) > 5:  # ì¶©ë¶„í•œ ì´ë²¤íŠ¸ê°€ ìˆì„ ë•Œë§Œ
                    visualizer.plot_dpmm_analysis(task_specific_stats)
                
            except Exception as e:
                print(f"  âš ï¸ Task visualization error: {e}")
            
            env.close()
        
        # ìµœì¢… ëª¨ë¸ ì €ì¥
        final_checkpoint_path = os.path.join(args.save_dir, "final_fixed_model")
        try:
            agent.save(final_checkpoint_path)
            print(f"ğŸ’¾ Final model saved: {final_checkpoint_path}")
        except Exception as e:
            print(f"âš ï¸ Final save error: {e}")
        
        # í•™ìŠµ í†µê³„ ì €ì¥
        stats_path = os.path.join(args.save_dir, "fixed_training_stats.npz")
        try:
            np.savez(stats_path, **all_training_stats)
            print(f"ğŸ“Š Training stats saved: {stats_path}")
        except Exception as e:
            print(f"âš ï¸ Stats save error: {e}")
        
        # ğŸ¨ ìµœì¢… ì¢…í•© ì‹œê°í™” ë° ë¶„ì„
        print(f"\nğŸ¨ Generating comprehensive analysis...")
        try:
            task_names = [task['name'] for task in tasks]
            
            # ì¢…í•© ë³´ê³ ì„œ ìƒì„±
            visualizer.create_comprehensive_report(all_training_stats, task_names)
            
            # Birth ë¬¸ì œ ìµœì¢… ë¶„ì„
            print(f"\nğŸ”¬ Final Birth Problem Analysis:")
            analyze_birth_problem(all_training_stats)
            
            # í•˜ì´í¼íŒŒë¼ë¯¸í„° íš¨ê³¼ ë¶„ì„ (ê°€ëŠ¥í•œ ê²½ìš°)
            if len(all_training_stats['birth_rate_history']) > 10:
                print(f"\nğŸ“ˆ Birth Rate Evolution Analysis:")
                birth_rates = all_training_stats['birth_rate_history']
                tau_history = all_training_stats['tau_birth_history']
                
                print(f"  â€¢ Initial birth rate: {birth_rates[0]:.1%}")
                print(f"  â€¢ Final birth rate: {birth_rates[-1]:.1%}")
                print(f"  â€¢ Average birth rate: {np.mean(birth_rates):.1%}")
                print(f"  â€¢ Birth rate std: {np.std(birth_rates):.1%}")
                print(f"  â€¢ Initial tau_birth: {tau_history[0]:.3f}")
                print(f"  â€¢ Final tau_birth: {tau_history[-1]:.3f}")
                print(f"  â€¢ Tau adaptation range: {max(tau_history) - min(tau_history):.3f}")
            
        except Exception as e:
            print(f"âš ï¸ Final visualization error: {e}")
        
        # ìµœì¢… ìš”ì•½ (ê°œì„ ëœ í˜•ì‹)
        print(f"\n" + "="*80)
        print(f"ğŸ‰ FIXED SB3-DPMM TRAINING COMPLETED!")
        print(f"="*80)
        
        total_episodes = len(all_training_stats['episode_rewards'])
        overall_avg_reward = np.mean(all_training_stats['episode_rewards'])
        final_clusters = all_training_stats['cluster_evolution'][-1] if all_training_stats['cluster_evolution'] else 0
        final_experts = all_training_stats['expert_evolution'][-1] if all_training_stats['expert_evolution'] else 0
        total_dpmm_events = len(all_training_stats['dpmm_events'])
        
        print(f"ğŸ“Š OVERALL STATISTICS:")
        print(f"  â€¢ Total episodes: {total_episodes}")
        print(f"  â€¢ Overall average reward: {overall_avg_reward:.2f}")
        print(f"  â€¢ Best episode reward: {max(all_training_stats['episode_rewards']):.2f}")
        print(f"  â€¢ Final clusters: {final_clusters}")
        print(f"  â€¢ Final experts: {final_experts}")
        print(f"  â€¢ Total DPMM events: {total_dpmm_events}")
        print(f"  â€¢ Successful tasks: {len([t for t in all_training_stats['tasks'] if not t.get('early_stop_triggered', False)])}/{len(tasks)}")
        
        print(f"\nğŸ”§ BIRTH CONTROL EFFECTIVENESS:")
        if all_training_stats['birth_rate_history']:
            avg_birth_rate = np.mean(all_training_stats['birth_rate_history'])
            print(f"  â€¢ Average birth rate: {avg_birth_rate:.1%} (target: {args.target_birth_rate:.1%})")
            print(f"  â€¢ Birth control: {'âœ… Effective' if avg_birth_rate < 0.2 else 'âš ï¸ Needs tuning'}")
        
        print(f"\nğŸ’¾ OUTPUT FILES:")
        print(f"  â€¢ Model: {final_checkpoint_path}")
        print(f"  â€¢ Statistics: {stats_path}")
        print(f"  â€¢ Plots: {args.save_dir}/")
        
        print(f"\nğŸš€ NEXT STEPS:")
        print(f"  1. Review generated plots in {args.save_dir}/")
        print(f"  2. Check birth rate analysis for parameter tuning")
        print(f"  3. Run hyperparameter sweep if needed")
        print(f"  4. Test final model on evaluation tasks")

    except Exception as e:
        print(f"âŒ Training failed with error: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        sim.close()

def load_or_create_tasks(tasks_file: str, episodes_per_task: int):
    """íƒœìŠ¤í¬ ë¡œë“œ ë˜ëŠ” ìƒì„± (ê°œì„ ëœ ë²„ì „)"""
    if os.path.exists(tasks_file):
        try:
            with open(tasks_file, 'r') as f:
                tasks = yaml.safe_load(f)
            print(f"âœ… Loaded {len(tasks)} tasks from {tasks_file}")
            return tasks
        except Exception as e:
            print(f"âš ï¸ Task file load error: {e}, creating default tasks")
    
    # ê¸°ë³¸ íƒœìŠ¤í¬ ìƒì„± (ë” ë‹¤ì–‘í•œ ì„¤ì •)
    default_tasks = [
        {
            'name': 'push_cube_basic',
            'instruction': 'Push the blue cube to the goal position',
            'env_cfg': {
                'cube_position': [2.0, 0.0, 0.1],
                'goal_position': [3.0, 0.0, 0.1],
                'cube_size': 0.2,
                'goal_tolerance': 0.3
            },
            'episodes': episodes_per_task
        },
        {
            'name': 'push_cube_far',
            'instruction': 'Move the cube to the distant target location',
            'env_cfg': {
                'cube_position': [2.0, 0.0, 0.1],
                'goal_position': [4.5, 0.0, 0.1],  # ë” ë©€ë¦¬
                'cube_size': 0.2,
                'goal_tolerance': 0.3
            },
            'episodes': episodes_per_task
        },
        {
            'name': 'push_cube_left',
            'instruction': 'Push the cube to the left side target',
            'env_cfg': {
                'cube_position': [2.0, 0.0, 0.1],
                'goal_position': [2.0, 2.5, 0.1],  # ì™¼ìª½ìœ¼ë¡œ
                'cube_size': 0.2,
                'goal_tolerance': 0.3
            },
            'episodes': episodes_per_task
        },
        {
            'name': 'push_cube_right',
            'instruction': 'Move the object to the right side goal',
            'env_cfg': {
                'cube_position': [2.0, 0.0, 0.1],
                'goal_position': [2.0, -2.5, 0.1],  # ì˜¤ë¥¸ìª½ìœ¼ë¡œ
                'cube_size': 0.2,
                'goal_tolerance': 0.3
            },
            'episodes': episodes_per_task
        },
        {
            'name': 'push_cube_diagonal',
            'instruction': 'Push the cube diagonally to the corner target',
            'env_cfg': {
                'cube_position': [2.0, 0.0, 0.1],
                'goal_position': [4.0, 2.0, 0.1],  # ëŒ€ê°ì„ 
                'cube_size': 0.2,
                'goal_tolerance': 0.3
            },
            'episodes': episodes_per_task
        },
        {
            'name': 'push_cube_precision',
            'instruction': 'Carefully move the cube to the precise target',
            'env_cfg': {
                'cube_position': [2.0, 0.0, 0.1],
                'goal_position': [3.0, 1.0, 0.1],
                'cube_size': 0.15,  # ì‘ì€ íë¸Œ
                'goal_tolerance': 0.2  # ì •ë°€í•œ ëª©í‘œ
            },
            'episodes': episodes_per_task
        }
    ]
    
    # íƒœìŠ¤í¬ íŒŒì¼ ì €ì¥
    try:
        with open(tasks_file, 'w') as f:
            yaml.dump(default_tasks, f, default_flow_style=False)
        print(f"ğŸ’¾ Saved default tasks to {tasks_file}")
    except Exception as e:
        print(f"âš ï¸ Could not save tasks file: {e}")
    
    print(f"âœ… Created {len(default_tasks)} default tasks")
    return default_tasks

if __name__ == "__main__":
    main()
